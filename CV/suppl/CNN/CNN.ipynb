{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2, time\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "train_path = glob.glob('./农民身份识别挑战赛公开数据/train/*')\n",
    "test_path = glob.glob('./农民身份识别挑战赛公开数据/test/*')\n",
    "\n",
    "train_path.sort()\n",
    "test_path.sort()\n",
    "\n",
    "train_df = pd.read_csv('农民身份识别挑战赛公开数据/train.csv')\n",
    "train_df = train_df.sort_values(by='name')\n",
    "train_label = train_df['label'].values\n",
    "\n",
    "# 自定义数据集\n",
    "# 带有图片缓存的逻辑\n",
    "DATA_CACHE = {}\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "    def __getitem__(self, index):\n",
    "        if self.img_path[index] in DATA_CACHE:\n",
    "            img = DATA_CACHE[self.img_path[index]]\n",
    "        else:\n",
    "            img = cv2.imread(self.img_path[index])\n",
    "            DATA_CACHE[self.img_path[index]] = img\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image = img)['image']\n",
    "        img = img.transpose([2,0,1])\n",
    "        return img, torch.from_numpy(np.array(self.img_label[index]))\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "        \n",
    "import albumentations as A\n",
    "# 训练集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(train_path[:-1000], train_label[:-1000],\n",
    "            A.Compose([\n",
    "            A.RandomRotate90(),\n",
    "            A.Resize(256, 256),\n",
    "            A.RandomCrop(224, 224),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomContrast(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    ), batch_size=30, shuffle=True, num_workers=1, pin_memory=False\n",
    ")\n",
    "\n",
    "# 验证集\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(train_path[-1000:], train_label[-1000:],\n",
    "            A.Compose([\n",
    "            A.Resize(256, 256),\n",
    "            A.RandomCrop(224, 224),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    ), batch_size=30, shuffle=False, num_workers=1, pin_memory=False\n",
    ")\n",
    "\n",
    "# 测试集\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(test_path, [0] * len(test_path),\n",
    "            A.Compose([\n",
    "            A.Resize(256, 256),\n",
    "            A.RandomCrop(224, 224),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomContrast(p=0.5),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    ), batch_size=2, shuffle=False, num_workers=1, pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XunFeiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet, self).__init__()\n",
    "        model = models.resnet18(True)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(512, 25)\n",
    "        self.resnet = model\n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "        \n",
    "model = XunFeiNet()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train(train_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Train loss', loss.item())\n",
    "            \n",
    "        train_loss += loss.item()\n",
    "    return train_loss/len(train_loader)\n",
    "\n",
    "# 模型验证       \n",
    "def validate(val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            val_acc += (output.argmax(1) == target).sum().item()\n",
    "            \n",
    "    return val_acc / len(val_loader.dataset)\n",
    "    \n",
    "# 模型预测\n",
    "def predict(test_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input)\n",
    "            test_pred.append(output.data.cpu().numpy())\n",
    "            \n",
    "    return np.vstack(test_pred)\n",
    "    \n",
    "for _  in range(1):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc  = validate(val_loader, model, criterion)\n",
    "    train_acc = validate(train_loader, model, criterion)\n",
    "    print(train_loss, train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对测试集多次预测\n",
    "pred = None\n",
    "for _ in range(3):\n",
    "    if pred is None:\n",
    "        pred = predict(test_loader, model, criterion)\n",
    "    else:\n",
    "        pred += predict(test_loader, model, criterion)\n",
    "submit = pd.DataFrame(\n",
    "    {\n",
    "        'name': [x.split('/')[-1] for x in test_path],\n",
    "        'label': pred.argmax(1)\n",
    "})\n",
    "\n",
    "# 生成提交结果\n",
    "submit = submit.sort_values(by='name')\n",
    "submit.to_csv('submit.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
