{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical Mission\n",
    "- `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
    "- `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
    "- `\"conversational\"`: will return a [`ConversationalPipeline`].\n",
    "- `\"depth-estimation\"`: will return a [`DepthEstimationPipeline`].\n",
    "- `\"document-question-answering\"`: will return a [`DocumentQuestionAnsweringPipeline`].\n",
    "- `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
    "- `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
    "- `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
    "- `\"image-segmentation\"`: will return a [`ImageSegmentationPipeline`].\n",
    "- `\"image-to-text\"`: will return a [`ImageToTextPipeline`].\n",
    "- `\"mask-generation\"`: will return a [`MaskGenerationPipeline`].\n",
    "- `\"object-detection\"`: will return a [`ObjectDetectionPipeline`].\n",
    "- `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
    "- `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
    "- `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
    "- `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
    "- `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
    "  [`TextClassificationPipeline`].\n",
    "- `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
    "- `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
    "- `\"translation\"`: will return a [`TranslationPipeline`].\n",
    "- `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
    "- `\"video-classification\"`: will return a [`VideoClassificationPipeline`].\n",
    "- `\"visual-question-answering\"`: will return a [`VisualQuestionAnsweringPipeline`].\n",
    "- `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
    "- `\"zero-shot-image-classification\"`: will return[`ZeroShotImageClassificationPipeline`].\n",
    "- `\"zero-shot-audio-classification\"`: will return[`ZeroShotAudioClassificationPipeline`].\n",
    "- `\"zero-shot-object-detection\"`: will return a [`ZeroShotObjectDetectionPipeline`]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8669572472572327}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline for classical NLP missions\n",
    "# Example: sentiment analysis\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"Some sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Special Tokens: \n",
    "- [CLS]: classification token, corresponing output vector represent the classification result, such a meaningless token support more fairly combination of text information.\n",
    "- [PAD]: padding token\n",
    "- [SEP]: segment token\n",
    "- [UNK]: unknown token\n",
    "- [MASK]: mask token\n",
    "\n",
    "Implementation: `transformers.PreTrainedTokenizer` or `transformers.PreTrainedTokenizer` (Base class for Tokenizer)\n",
    "\n",
    "Output format: dict\n",
    "- `input_ids`: indice of tokens (tokens_tensor)\n",
    "- `token_type_ids`: sentence segmentation, 0-firstsentence; 1-second sentence (segments_tensor)\n",
    "- `attention_mask`: 1 indicate attention requiredfor this token (mask_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.tokenization_bert_fast.BertTokenizerFast"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer: BertTokenizerFast = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 1010, 14324, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly callable\n",
    "raw_sentence: str = \"Hello, BERT\"\n",
    "tokenizer(raw_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'bert']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(raw_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 1010, 14324, 102]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_sentence = tokenizer.encode(raw_sentence)\n",
    "encode_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hello, bert [SEP]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encode_sentence, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.modeling_bert.BertModel"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "bert: BertModel = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "type(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.29.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 5.7107e-02,  2.5669e-01, -9.5842e-02,  ..., -1.2954e-01,\n",
       "           5.1437e-01,  5.7981e-01],\n",
       "         [ 1.9249e-01,  3.8698e-01, -3.5842e-01,  ...,  3.5617e-01,\n",
       "           9.1635e-01,  3.7469e-01],\n",
       "         [ 1.8221e-01,  1.3408e-01,  9.1152e-01,  ..., -6.2215e-02,\n",
       "           6.5364e-01,  4.2190e-01],\n",
       "         ...,\n",
       "         [ 4.7319e-01,  4.3217e-01,  9.9005e-01,  ..., -9.9500e-04,\n",
       "           3.9321e-01,  8.0758e-01],\n",
       "         [-3.5663e-01, -2.3165e-01, -5.6852e-01,  ...,  9.7276e-01,\n",
       "           5.3078e-01, -3.6599e-02],\n",
       "         [ 9.1939e-01,  2.7100e-01, -7.1249e-02,  ..., -7.5035e-02,\n",
       "          -6.7383e-01, -1.5287e-01]],\n",
       "\n",
       "        [[-3.1059e-02,  4.1652e-01, -2.8671e-01,  ...,  2.3529e-03,\n",
       "           2.7787e-01,  4.6885e-01],\n",
       "         [-2.7230e-02, -1.7579e-02,  5.1009e-02,  ...,  8.4250e-02,\n",
       "           5.9173e-01, -4.7261e-02],\n",
       "         [-1.0027e+00,  6.8936e-01,  4.3878e-01,  ..., -6.8877e-01,\n",
       "           2.1533e-01, -8.2567e-02],\n",
       "         ...,\n",
       "         [-1.4581e-01,  4.0352e-01,  6.4841e-01,  ...,  1.0245e-01,\n",
       "           1.4671e-01,  6.4706e-02],\n",
       "         [-4.5045e-02,  2.9193e-01,  5.1686e-01,  ...,  1.3623e-01,\n",
       "           1.2511e-01, -9.5616e-03],\n",
       "         [ 1.7460e-02,  2.2534e-01,  5.4954e-01,  ...,  8.3629e-02,\n",
       "           6.9846e-02,  1.5765e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8473, -0.3063, -0.1994,  ..., -0.0371, -0.6173,  0.8766],\n",
       "        [-0.6468, -0.2609, -0.6894,  ..., -0.6594, -0.5741,  0.8214]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def to_tensor(src: dict[str, list[int]]) -> dict[str, torch.LongTensor]:\n",
    "    for k, v in src.items():\n",
    "        src[k] = torch.LongTensor(v)\n",
    "    return src\n",
    "\n",
    "corpus: list[str] = [\"I like PyTorch\", \"Hello, BERT\"]\n",
    "src: dict[str, list[int]] = tokenizer(corpus, padding=True, truncation=True)\n",
    "result_dict = bert(**to_tensor(src))\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_hidden_state: torch.Size([2, 8, 768])\n",
      "pooler_output: torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "# Output Dimension: \n",
    "# \"last_hidden_state\": batch_size * token_counts * 768 \n",
    "# \"last_hidden_state\": batch_size  * 768 \n",
    "for k, v in result_dict.items():\n",
    "    print(f'{k}: {result_dict[k].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
