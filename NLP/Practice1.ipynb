{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 -- Baseline Analysis\n",
    "### Mission Description\n",
    "- Mission 1: Classification (Predict the label of literatures)\n",
    "- Mission 2: Keywords Extraction \n",
    "\n",
    "### Feature Extraction\n",
    "1. TF-IDF Algorithm: `TfidfVectorizer`  \n",
    "    TF (Term Frequency): frequence of word occurance in document.  \n",
    "    $$ \n",
    "    TF = \\frac{\\#SpecificWordOfDoc}{\\#TotalWordOfDoc}\n",
    "    $$\n",
    "    IDF (Inverse Document Frequency): metric to evaluate the weight of word. The high value means a unnormal word.\n",
    "    $$\n",
    "    IDF = log(\\frac{\\#DocInCorpus}{\\#DocWithinSpecificWord + 1})\n",
    "    $$\n",
    "    The importance of a specific word positively correlate to its occurance in document, and negatively to its occurance in Corpus.\n",
    "    $$\n",
    "    TF-IDF = TF * IDF\n",
    "    $$\n",
    "    \n",
    "    \n",
    "2. BOW (Bag Of Words) model: `CountVectorizer`\n",
    "\n",
    "Operation: Just extract features through `sklearn` package.\n",
    "\n",
    "### Keyword Extraction\n",
    "**Tokenization**: Break unstructured data and natural language text into chunks of information that can be considered as discrete elements.  \n",
    "[Blog - Introduction of Tokenization in NLP](https://neptune.ai/blog/tokenization-in-nlp)\n",
    "\n",
    "\n",
    "**N-grams**: sequence of N words.  \n",
    "[Blog - Introduction of N-grams](https://blog.xrds.acm.org/2017/10/introduction-n-grams-need/)\n",
    "\n",
    "1. `word_tokenize`\n",
    "2. `ngrams`\n",
    "\n",
    "Operation:\n",
    "1. Stop word removal\n",
    "2. Extract keywords through frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk import word_tokenize, ngrams\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Raw Data and Preprocessing\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "train['title'] = train['title'].fillna('')\n",
    "train['abstract'] = train['abstract'].fillna('')\n",
    "\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "test['title'] = test['title'].fillna('')\n",
    "test['abstract'] = test['abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>abstract</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Accessible Visual Artworks for Blind and Visua...</td>\n",
       "      <td>Quero, Luis Cavazos; Bartolome, Jorge Iranzo; ...</td>\n",
       "      <td>Despite the use of tactile graphics and audio ...</td>\n",
       "      <td>accessibility technology; multimodal interacti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Seizure Detection and Prediction by Parallel M...</td>\n",
       "      <td>Li, Chenqi; Lammie, Corey; Dong, Xuening; Amir...</td>\n",
       "      <td>During the past two decades, epileptic seizure...</td>\n",
       "      <td>CNN; Seizure Detection; Seizure Prediction; EE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Fast ScanNet: Fast and Dense Analysis of Multi...</td>\n",
       "      <td>Lin, Huangjing; Chen, Hao; Graham, Simon; Dou,...</td>\n",
       "      <td>Lymph node metastasis is one of the most impor...</td>\n",
       "      <td>Histopathology image analysis; computational p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Long-Term Effectiveness of Antiretroviral Ther...</td>\n",
       "      <td>Huang, Peng; Tan, Jingguang; Ma, Wenzhe; Zheng...</td>\n",
       "      <td>In order to assess the effectiveness of the Ch...</td>\n",
       "      <td>HIV; ART; mortality; observational cohort stud...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Real-Time Facial Affective Computing on Mobile...</td>\n",
       "      <td>Guo, Yuanyuan; Xia, Yifan; Wang, Jing; Yu, Hui...</td>\n",
       "      <td>Convolutional Neural Networks (CNNs) have beco...</td>\n",
       "      <td>facial affective computing; convolutional neur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uuid                                              title  \\\n",
       "0     0  Accessible Visual Artworks for Blind and Visua...   \n",
       "1     1  Seizure Detection and Prediction by Parallel M...   \n",
       "2     2  Fast ScanNet: Fast and Dense Analysis of Multi...   \n",
       "3     3  Long-Term Effectiveness of Antiretroviral Ther...   \n",
       "4     4  Real-Time Facial Affective Computing on Mobile...   \n",
       "\n",
       "                                              author  \\\n",
       "0  Quero, Luis Cavazos; Bartolome, Jorge Iranzo; ...   \n",
       "1  Li, Chenqi; Lammie, Corey; Dong, Xuening; Amir...   \n",
       "2  Lin, Huangjing; Chen, Hao; Graham, Simon; Dou,...   \n",
       "3  Huang, Peng; Tan, Jingguang; Ma, Wenzhe; Zheng...   \n",
       "4  Guo, Yuanyuan; Xia, Yifan; Wang, Jing; Yu, Hui...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Despite the use of tactile graphics and audio ...   \n",
       "1  During the past two decades, epileptic seizure...   \n",
       "2  Lymph node metastasis is one of the most impor...   \n",
       "3  In order to assess the effectiveness of the Ch...   \n",
       "4  Convolutional Neural Networks (CNNs) have beco...   \n",
       "\n",
       "                                            Keywords  label  \n",
       "0  accessibility technology; multimodal interacti...      0  \n",
       "1  CNN; Seizure Detection; Seizure Prediction; EE...      1  \n",
       "2  Histopathology image analysis; computational p...      1  \n",
       "3  HIV; ART; mortality; observational cohort stud...      0  \n",
       "4  facial affective computing; convolutional neur...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>abstract</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Monitoring Changes in Intracellular Reactive O...</td>\n",
       "      <td>Al-Hassan M Mustafa,Ramy Ashry,Oliver H Krämer...</td>\n",
       "      <td>Reactive oxygen species (ROS) are induced by s...</td>\n",
       "      <td>Flow cytometry; HDACi; Leukemia; ROS.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Source Printer Classification Using Printer Sp...</td>\n",
       "      <td>Joshi, Sharad; Khanna, Nitin</td>\n",
       "      <td>The knowledge of the source printer can help i...</td>\n",
       "      <td>Printer classification; local texture patterns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Plasma-processed CoSn/RGO nanocomposite: A low...</td>\n",
       "      <td>Omelianovych, Oleksii; Larina, Liudmila L.; Oh...</td>\n",
       "      <td>The high cost of state-of-the-art Pt counter e...</td>\n",
       "      <td>Plasma reduction; Bimatalic alloy CoxSn1-x; Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Immediate Antiretroviral Therapy: The Need for...</td>\n",
       "      <td>Mgbako, Ofole; E. Sobieszczyk, Magdalena; Olen...</td>\n",
       "      <td>Immediate antiretroviral therapy (iART), defin...</td>\n",
       "      <td>HIV; antiretroviral therapy; rapid; health equity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Design and analysis of an ultra-low-power LC q...</td>\n",
       "      <td>Lee, Kin Keung; Bryant, Carl; Tormanen, Markus...</td>\n",
       "      <td>This paper presents the design of an ultra-low...</td>\n",
       "      <td>Varactor; Spiral inductor; Quadrature generati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uuid                                              title  \\\n",
       "0     0  Monitoring Changes in Intracellular Reactive O...   \n",
       "1     1  Source Printer Classification Using Printer Sp...   \n",
       "2     2  Plasma-processed CoSn/RGO nanocomposite: A low...   \n",
       "3     3  Immediate Antiretroviral Therapy: The Need for...   \n",
       "4     4  Design and analysis of an ultra-low-power LC q...   \n",
       "\n",
       "                                              author  \\\n",
       "0  Al-Hassan M Mustafa,Ramy Ashry,Oliver H Krämer...   \n",
       "1                       Joshi, Sharad; Khanna, Nitin   \n",
       "2  Omelianovych, Oleksii; Larina, Liudmila L.; Oh...   \n",
       "3  Mgbako, Ofole; E. Sobieszczyk, Magdalena; Olen...   \n",
       "4  Lee, Kin Keung; Bryant, Carl; Tormanen, Markus...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Reactive oxygen species (ROS) are induced by s...   \n",
       "1  The knowledge of the source printer can help i...   \n",
       "2  The high cost of state-of-the-art Pt counter e...   \n",
       "3  Immediate antiretroviral therapy (iART), defin...   \n",
       "4  This paper presents the design of an ultra-low...   \n",
       "\n",
       "                                            Keywords  \n",
       "0              Flow cytometry; HDACi; Leukemia; ROS.  \n",
       "1  Printer classification; local texture patterns...  \n",
       "2  Plasma reduction; Bimatalic alloy CoxSn1-x; Re...  \n",
       "3  HIV; antiretroviral therapy; rapid; health equity  \n",
       "4  Varactor; Spiral inductor; Quadrature generati...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration (Prepare for Feature Extraction)\n",
    "train['text'] = train['title'] + ' ' + train['author'].fillna('') + ' ' + train['abstract'] + train['Keywords'].fillna('')\n",
    "test['text'] = test['title'] + ' ' + test['author'].fillna('') + ' ' + test['abstract'] + test['Keywords'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Model\n",
    "vm = TfidfVectorizer()\n",
    "# print(vm.vocabulary_)  # 'term:incidce' dict\n",
    "# print(vm.idf_)  # IDF vector\n",
    "\n",
    "# BOW Model\n",
    "# vm = CountVectorizer()\n",
    "# print(vm.vocabulary_)  # 'term:incidce' dict\n",
    "\n",
    "# Transform datasets\n",
    "vector = vm.fit(train['text'])\n",
    "train_vector = vector.transform(train['text'])\n",
    "test_vector = vector.transform(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 65446)\t0.030549364150652764\n",
      "  (0, 65318)\t0.02444242755778677\n",
      "  (0, 65077)\t0.028246014053659677\n",
      "  (0, 65064)\t0.029621156367709178\n",
      "  (0, 64735)\t0.045579794197544786\n",
      "  (0, 64139)\t0.18451628473970147\n",
      "  (0, 64129)\t0.14963072908017255\n",
      "  (0, 64116)\t0.040629329389665736\n",
      "  (0, 63711)\t0.06799786078737419\n",
      "  (0, 63115)\t0.04117265806080924\n",
      "  (0, 63114)\t0.049814452337536036\n",
      "  (0, 63104)\t0.08489887630119931\n",
      "  (0, 63095)\t0.06580743475418266\n",
      "  (0, 62619)\t0.04564370573228639\n",
      "  (0, 62164)\t0.02391576337827588\n",
      "  (0, 61137)\t0.27723453687872074\n",
      "  (0, 60831)\t0.07228570446246294\n",
      "  (0, 60352)\t0.012362244765386258\n",
      "  (0, 60207)\t0.03270267777936728\n",
      "  (0, 60171)\t0.08841011496442515\n",
      "  (0, 60162)\t0.024068278327935694\n",
      "  (0, 60149)\t0.07872629173608289\n",
      "  (0, 60136)\t0.03951871431621518\n",
      "  (0, 59683)\t0.036425241093392825\n",
      "  (0, 59174)\t0.2945830456249297\n",
      "  :\t:\n",
      "  (5999, 17533)\t0.31504007312955895\n",
      "  (5999, 15906)\t0.11619793197754757\n",
      "  (5999, 15797)\t0.09401162905085142\n",
      "  (5999, 15385)\t0.023249449153589008\n",
      "  (5999, 14079)\t0.045446057918805204\n",
      "  (5999, 13570)\t0.12484925427046632\n",
      "  (5999, 10092)\t0.020996380675379338\n",
      "  (5999, 9715)\t0.015345683229027006\n",
      "  (5999, 9499)\t0.05022168632344902\n",
      "  (5999, 7723)\t0.05021086448587289\n",
      "  (5999, 7530)\t0.06463150882075451\n",
      "  (5999, 7456)\t0.05623810057336043\n",
      "  (5999, 7324)\t0.024640281537267772\n",
      "  (5999, 6378)\t0.058477027818789815\n",
      "  (5999, 5822)\t0.03339134975648937\n",
      "  (5999, 5510)\t0.03116392400125249\n",
      "  (5999, 5456)\t0.04752409115351966\n",
      "  (5999, 5295)\t0.06346084102391693\n",
      "  (5999, 5273)\t0.1410313441851488\n",
      "  (5999, 5272)\t0.04015738485319501\n",
      "  (5999, 4386)\t0.061854384263354725\n",
      "  (5999, 3916)\t0.02344668239146282\n",
      "  (5999, 3843)\t0.09192521355264165\n",
      "  (5999, 2654)\t0.05738242605089129\n",
      "  (5999, 2413)\t0.03206356002950831\n"
     ]
    }
   ],
   "source": [
    "print(train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model = LogisticRegression()\n",
    "model.fit(train_vector, train['label'])\n",
    "test['label'] = model.predict(test_vector)\n",
    "test[['uuid', 'Keywords', 'label']].to_csv(\"./submit/task3_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Words Definition\n",
    "stops = [\n",
    "    'will', 'can', \"couldn't\", 'same', 'own', \"needn't\", 'between', \"shan't\", 'very',\n",
    "     'so', 'over', 'in', 'have', 'the', 's', 'didn', 'few', 'should', 'of', 'that', \n",
    "     'don', 'weren', 'into', \"mustn't\", 'other', 'from', \"she's\", 'hasn', \"you're\",\n",
    "     'ain', 'ours', 'them', 'he', 'hers', 'up', 'below', 'won', 'out', 'through',\n",
    "     'than', 'this', 'who', \"you've\", 'on', 'how', 'more', 'being', 'any', 'no',\n",
    "     'mightn', 'for', 'again', 'nor', 'there', 'him', 'was', 'y', 'too', 'now',\n",
    "     'whom', 'an', 've', 'or', 'itself', 'is', 'all', \"hasn't\", 'been', 'themselves',\n",
    "     'wouldn', 'its', 'had', \"should've\", 'it', \"you'll\", 'are', 'be', 'when', \"hadn't\",\n",
    "     \"that'll\", 'what', 'while', 'above', 'such', 'we', 't', 'my', 'd', 'i', 'me',\n",
    "     'at', 'after', 'am', 'against', 'further', 'just', 'isn', 'haven', 'down',\n",
    "     \"isn't\", \"wouldn't\", 'some', \"didn't\", 'ourselves', 'their', 'theirs', 'both',\n",
    "     're', 'her', 'ma', 'before', \"don't\", 'having', 'where', 'shouldn', 'under',\n",
    "     'if', 'as', 'myself', 'needn', 'these', 'you', 'with', 'yourself', 'those',\n",
    "     'each', 'herself', 'off', 'to', 'not', 'm', \"it's\", 'does', \"weren't\", \"aren't\",\n",
    "     'were', 'aren', 'by', 'doesn', 'himself', 'wasn', \"you'd\", 'once', 'because', 'yours',\n",
    "     'has', \"mightn't\", 'they', 'll', \"haven't\", 'but', 'couldn', 'a', 'do', 'hadn',\n",
    "     \"doesn't\", 'your', 'she', 'yourselves', 'o', 'our', 'here', 'and', 'his', 'most',\n",
    "     'about', 'shan', \"wasn't\", 'then', 'only', 'mustn', 'doing', 'during', 'why',\n",
    "     \"won't\", 'until', 'did', \"shouldn't\", 'which'\n",
    "]\n",
    "\n",
    "# Keywords Extraction By Frequency\n",
    "def extract_keywords_by_freq(title: str, abstract: str) -> list:\n",
    "    # Tokenize \n",
    "    ngrams_count = list(ngrams(word_tokenize(title.lower()), 2)) + list(ngrams(word_tokenize(abstract.lower()), 2))\n",
    "    ngrams_count = pd.DataFrame(ngrams_count)\n",
    "    # Filter by stop words and length of words\n",
    "    for i in range(ngrams_count.shape[1]):\n",
    "        ngrams_count = ngrams_count[~ngrams_count[i].isin(stops)]\n",
    "        ngrams_count = ngrams_count[ngrams_count[i].apply(len) > 3]\n",
    "    # Concate words into phrase\n",
    "    ngrams_count['phrase'] = ngrams_count.apply(lambda x: \" \".join([i for i in x]), axis=1)\n",
    "    ngrams_count = ngrams_count['phrase'].value_counts()\n",
    "    # Filter by frequency\n",
    "    ngrams_count = ngrams_count[ngrams_count > 1]\n",
    "    return list(ngrams_count.index)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_keywords = []\n",
    "for row in test.iterrows():\n",
    "    pred_keywords = extract_keywords_by_freq(row[1].title, row[1].abstract)\n",
    "    # Capitalize first letter of each word\n",
    "    pred_keywords = [x.title() for x in pred_keywords]\n",
    "    if len(pred_keywords) == 0:\n",
    "        pred_keywords = ['A', 'B']\n",
    "    test_keywords.append(\"; \".join(pred_keywords))\n",
    "\n",
    "test['Keywords'] = test_keywords\n",
    "test[['uuid', 'Keywords', 'label']].to_csv('./submit/task2_baseline.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-diffusion-webui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
