{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面提供bert模型解决关键词提取的思路  \n",
    "当我们想从特定文档中了解关键信息时，通常会转向关键词提取（keyword extraction）。关键词提取（keyword extraction）是提取与输入文本最相关的词汇、短语的自动化过程。  \n",
    "目前已经有很多的集成工具库类似KeyBERT，已经能够达到非常好的效果，但是在这里我们选择使用BERT创建自己的关键词提取模型，来帮助大家更好的完成文本关键词提取的整个流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入前置依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入pandas用于读取表格数据\n",
    "import pandas as pd\n",
    "\n",
    "# 导入BOW（词袋模型），可以选择将CountVectorizer替换为TfidfVectorizer（TF-IDF（词频-逆文档频率）），注意上下文要同时修改，亲测后者效果更佳\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 导入Bert模型\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 导入计算相似度前置库，为了计算候选者和文档之间的相似度，我们将使用向量之间的余弦相似度，因为它在高维度下表现得相当好。\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 过滤警告消息\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird', 'cat', 'dog', 'fish']\n",
      "{'dog': 2, 'cat': 1, 'fish': 3, 'bird': 0}\n",
      "  (0, 3)\t0.5773502691896257\n",
      "  (0, 1)\t0.5773502691896257\n",
      "  (0, 2)\t0.5773502691896257\n",
      "  (1, 1)\t0.8944271909999159\n",
      "  (1, 2)\t0.4472135954999579\n",
      "  (2, 0)\t0.7071067811865475\n",
      "  (2, 3)\t0.7071067811865475\n",
      "  (3, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "texts=[\"dog cat fish\",\"dog cat cat\",\"fish bird\", 'bird'] # “dog cat fish” 为输入列表元素,即代表一个文章的字符串\n",
    "cv = TfidfVectorizer()#创建词袋数据结构\n",
    "cv_fit=cv.fit_transform(texts)\n",
    "#上述代码等价于下面两行\n",
    "#cv.fit(texts)\n",
    "#cv_fit=cv.transform(texts)\n",
    "\n",
    "print(cv.get_feature_names())    #['bird', 'cat', 'dog', 'fish'] 列表形式呈现文章生成的词典\n",
    "\n",
    "print(cv.vocabulary_\t)              # {‘dog’:2,'cat':1,'fish':3,'bird':0} 字典形式呈现，key：词，value:词频\n",
    "\n",
    "print(cv_fit)      # 第n个列表元素，**词典中索引为n的元素**， 词频\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据集并处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "test = pd.read_csv('./基于论文摘要的文本分类与关键词抽取挑战赛公开数据/test.csv')\n",
    "test['title'] = test['title'].fillna('')\n",
    "test['abstract'] = test['abstract'].fillna('')\n",
    "\n",
    "\n",
    "test['text'] = test['title'].fillna('') + ' ' +test['abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义停用词，去掉出现较多，但对文章不关键的词语\n",
    "stops =[i.strip() for i in open(r'stop.txt',encoding='utf-8').readlines()] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们使用distiluse-base-multilingual-cased，因为它在相似性任务中表现出了很好的性能，这也是我们对关键词/关键短语提取的目标!\n",
    "由于transformer模型有token长度限制，所以在输入大型文档时，你可能会遇到一些错误。在这种情况下，您可以考虑将您的文档分割成几个小的段落，并对其产生的向量进行平均池化（mean pooling ，要取平均值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(r'xlm-r-distilroberta-base-paraphrase-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "c:\\Users\\lima\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'al', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  % sorted(inconsistent)\n"
     ]
    }
   ],
   "source": [
    "test_words = []\n",
    "for row in test.iterrows():\n",
    "    # 读取第每一行数据的标题与摘要并提取关键词\n",
    "    \n",
    "    n_gram_range = (2,2)\n",
    "    # 这里我们使用TF-IDF算法来获取候选关键词 \n",
    "    count = TfidfVectorizer(ngram_range=n_gram_range, stop_words=stops).fit([row[1].text])\n",
    "    candidates = count.get_feature_names_out()\n",
    "    # 将文本标题以及候选关键词/关键短语转换为数值型数据（numerical data）。我们使用BERT来实现这一目的\n",
    "    title_embedding = model.encode([row[1].title])\n",
    "    \n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "    \n",
    "    # 通过修改这个参数来更改关键词数量\n",
    "    top_n = 15\n",
    "    # 利用文章标题进一步提取关键词\n",
    "    distances = cosine_similarity(title_embedding, candidate_embeddings)\n",
    "    keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
    "    \n",
    "    if len( keywords) == 0:\n",
    "         keywords = ['A', 'B']\n",
    "    test_words.append('; '.join( keywords))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到结果，最后输出为要求格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Keywords'] = test_words\n",
    "test[['uuid', 'Keywords']].to_csv('submit_task2.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
