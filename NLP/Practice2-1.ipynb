{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 -- BERT Application 1\n",
    "- Mission1: Binary Classification * \n",
    "- Mission2: Keywords Extraction\n",
    "\n",
    "### Introduction of BERT\n",
    "\n",
    "\n",
    "### Usage\n",
    "1. Tokenizer  [Doc](https://huggingface.co/transformers/v3.0.2/main_classes/tokenizer.html)  \n",
    "    Output format: dict\n",
    "    - `input_ids`: indice of tokens (tokens_tensor)\n",
    "    - `token_type_ids`: sentence segmentation, 0-first sentence; 1-second sentence (segments_tensor)\n",
    "    - `attention_mask`: 1 indicate attention required for this token (mask_tensor)\n",
    "2. Model  [Doc](https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#bertmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizerFast, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Global Parameter Initialization\n",
    "batch_size = 16\n",
    "text_max_length = 128\n",
    "epochs = 100\n",
    "lr = 3e-5\n",
    "validation_ratio = 0.1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging_per_step = 50\n",
    "\n",
    "dataset_dir = Path('./data/')\n",
    "model_dir = Path('./models/bert-checkpoints/classification/')\n",
    "os.makedirs(model_dir) if not os.path.exists(model_dir) else ''\n",
    "\n",
    "print(f'Device: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Preprocessing\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "train_data['title'] = train_data['title'].fillna('')\n",
    "train_data['abstract'] = train_data['abstract'].fillna('')\n",
    "\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "test_data['title'] = test_data['title'].fillna('')\n",
    "test_data['abstract'] = test_data['abstract'].fillna('')\n",
    "\n",
    "# Integration\n",
    "train_data['text'] = train_data['title'] + ' ' + train_data['author'].fillna('') + ' ' + train_data['abstract'] + train_data['Keywords'].fillna('')\n",
    "test_data['text'] = test_data['title'] + ' ' + test_data['author'].fillna('') + ' ' + test_data['abstract'] + test_data['Keywords'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Validation Dataset\n",
    "validation_data = train_data.sample(frac=validation_ratio)\n",
    "train_data = train_data[~train_data.index.isin(validation_data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Definition\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, mode: str = 'train') -> None:\n",
    "        super().__init__()\n",
    "        self.mode: str = mode\n",
    "        if mode == 'train':\n",
    "            self.dataset: pd.DataFrame = train_data\n",
    "        elif mode == 'validation':\n",
    "            self.dataset: pd.DataFrame = validation_data\n",
    "        elif mode == 'test':\n",
    "            self.dataset: pd.DataFrame = test_data\n",
    "        else:\n",
    "            raise Exception(f'Unknown mode \"{mode}\"')\n",
    "        \n",
    "    def __getitem__(self, index: int) -> (str, int):\n",
    "        data = self.dataset.iloc[index]\n",
    "        text = data['text']\n",
    "        if self.mode == 'test':\n",
    "            label = data['uuid']\n",
    "        else:\n",
    "            label = data['label']\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "train_dataset = CustomDataset('train')\n",
    "validation_dataset = CustomDataset(\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained Tokenizer\n",
    "tokenizer: BertTokenizerFast = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch: tuple[str, int]) -> (dict[str, torch.Tensor], torch.LongTensor):\n",
    "    \"\"\"\n",
    "    Transform sentence into tensor, and form batch\n",
    "    \"\"\"\n",
    "    text, label = zip(*batch)\n",
    "    text, label = list(text), list(label)\n",
    "\n",
    "    # Generate input source to BERT model\n",
    "    # padding: fulfill short sentence\n",
    "    # truncation: truncate long sentence\n",
    "    src: dict[str, torch.Tensor] = tokenizer(text, padding=\"max_length\", max_length=text_max_length, return_tensors='pt', truncation=True)\n",
    "\n",
    "    return src, torch.LongTensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader: DataLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "validation_loader: DataLoader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: {'input_ids': tensor([[  101, 13228,  9324,  ...,  5265,  1997,   102],\n",
      "        [  101,  1996,  3894,  ...,  2038,  4719,   102],\n",
      "        [  101, 15873,  5107,  ..., 11443,  1996,   102],\n",
      "        ...,\n",
      "        [  101,  1037,  3319,  ...,  2024, 13047,   102],\n",
      "        [  101,  1037,  3117,  ...,  1011, 18215,   102],\n",
      "        [  101,  1056, 21693,  ...,  5524,  1044,   102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "targets: tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = next(iter(train_loader))\n",
    "print(f'inputs: {inputs}')\n",
    "print(f'targets: {targets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "# BERT Model + Prediction Layer\n",
    "class CustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.bert: BertModel = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.predictor: nn.Sequential = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, src: dict):\n",
    "        outputs = self.bert(**src).last_hidden_state[:, 0, :]\n",
    "        return self.predictor(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = CustomModel()\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss Function: Binary Cross Entropy\n",
    "citeria = nn.BCELoss()\n",
    "# Optimizer: Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(dict_tensors: dict[str, torch.Tensor]):\n",
    "    result_tensors: dict = {}\n",
    "    for k, v in dict_tensors.items():\n",
    "        result_tensors[k] = v.to(device)\n",
    "    return result_tensors\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for inputs, targets in validation_loader:\n",
    "        inputs, targets = to_device(inputs), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = citeria(outputs.view(-1), targets.float())\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        correct_num = (((outputs > 0.5).float() * 1).flatten() == targets).sum()\n",
    "        total_correct += correct_num\n",
    "    \n",
    "    return total_correct / len(validation_dataset), total_loss / len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Step: 50/338, Total Loss: 16.1978\n",
      "Epoch 1/100, Step: 100/338, Total Loss: 7.0319\n",
      "Epoch 1/100, Step: 150/338, Total Loss: 5.4716\n",
      "Epoch 1/100, Step: 200/338, Total Loss: 5.1327\n",
      "Epoch 1/100, Step: 250/338, Total Loss: 5.4352\n",
      "Epoch 1/100, Step: 300/338, Total Loss: 6.0479\n",
      "Epoch 1, accuracy: 0.9633, validation Loss: 0.0061\n",
      "\n",
      "Epoch 2/100, Step: 12/338, Total Loss: 5.7042\n",
      "Epoch 2/100, Step: 62/338, Total Loss: 4.0575\n",
      "Epoch 2/100, Step: 112/338, Total Loss: 2.1664\n",
      "Epoch 2/100, Step: 162/338, Total Loss: 3.9270\n",
      "Epoch 2/100, Step: 212/338, Total Loss: 2.7538\n",
      "Epoch 2/100, Step: 262/338, Total Loss: 3.4065\n",
      "Epoch 2/100, Step: 312/338, Total Loss: 4.6778\n",
      "Epoch 2, accuracy: 0.9583, validation Loss: 0.0098\n",
      "\n",
      "Epoch 3/100, Step: 24/338, Total Loss: 3.7689\n",
      "Epoch 3/100, Step: 74/338, Total Loss: 2.1891\n",
      "Epoch 3/100, Step: 124/338, Total Loss: 1.9464\n",
      "Epoch 3/100, Step: 174/338, Total Loss: 2.7616\n",
      "Epoch 3/100, Step: 224/338, Total Loss: 2.8268\n",
      "Epoch 3/100, Step: 274/338, Total Loss: 2.5298\n",
      "Epoch 3/100, Step: 324/338, Total Loss: 2.0593\n",
      "Epoch 3, accuracy: 0.9567, validation Loss: 0.0081\n",
      "\n",
      "Epoch 4/100, Step: 36/338, Total Loss: 2.7208\n",
      "Epoch 4/100, Step: 86/338, Total Loss: 1.9205\n",
      "Epoch 4/100, Step: 136/338, Total Loss: 1.0248\n",
      "Epoch 4/100, Step: 186/338, Total Loss: 1.3624\n",
      "Epoch 4/100, Step: 236/338, Total Loss: 1.0614\n",
      "Epoch 4/100, Step: 286/338, Total Loss: 2.2353\n",
      "Epoch 4/100, Step: 336/338, Total Loss: 1.9377\n",
      "Epoch 4, accuracy: 0.9583, validation Loss: 0.0099\n",
      "\n",
      "Epoch 5/100, Step: 48/338, Total Loss: 1.3893\n",
      "Epoch 5/100, Step: 98/338, Total Loss: 2.1568\n",
      "Epoch 5/100, Step: 148/338, Total Loss: 2.8561\n",
      "Epoch 5/100, Step: 198/338, Total Loss: 2.0382\n",
      "Epoch 5/100, Step: 248/338, Total Loss: 1.3103\n",
      "Epoch 5/100, Step: 298/338, Total Loss: 0.5234\n",
      "Epoch 5, accuracy: 0.9483, validation Loss: 0.0115\n",
      "\n",
      "Epoch 6/100, Step: 10/338, Total Loss: 2.2965\n",
      "Epoch 6/100, Step: 60/338, Total Loss: 0.7200\n",
      "Epoch 6/100, Step: 110/338, Total Loss: 0.4289\n",
      "Epoch 6/100, Step: 160/338, Total Loss: 0.3522\n",
      "Epoch 6/100, Step: 210/338, Total Loss: 0.7747\n",
      "Epoch 6/100, Step: 260/338, Total Loss: 0.6052\n",
      "Epoch 6/100, Step: 310/338, Total Loss: 1.6051\n",
      "Epoch 6, accuracy: 0.9650, validation Loss: 0.0086\n",
      "\n",
      "Epoch 7/100, Step: 22/338, Total Loss: 0.9688\n",
      "Epoch 7/100, Step: 72/338, Total Loss: 0.5135\n",
      "Epoch 7/100, Step: 122/338, Total Loss: 0.4798\n",
      "Epoch 7/100, Step: 172/338, Total Loss: 0.7102\n",
      "Epoch 7/100, Step: 222/338, Total Loss: 0.1848\n",
      "Epoch 7/100, Step: 272/338, Total Loss: 0.0413\n",
      "Epoch 7/100, Step: 322/338, Total Loss: 0.0344\n",
      "Epoch 7, accuracy: 0.9617, validation Loss: 0.0125\n",
      "\n",
      "Epoch 8/100, Step: 34/338, Total Loss: 0.3378\n",
      "Epoch 8/100, Step: 84/338, Total Loss: 0.0389\n",
      "Epoch 8/100, Step: 134/338, Total Loss: 0.0332\n",
      "Epoch 8/100, Step: 184/338, Total Loss: 0.0200\n",
      "Epoch 8/100, Step: 234/338, Total Loss: 0.1421\n",
      "Epoch 8/100, Step: 284/338, Total Loss: 0.1500\n",
      "Epoch 8/100, Step: 334/338, Total Loss: 0.0581\n",
      "Epoch 8, accuracy: 0.9633, validation Loss: 0.0168\n",
      "\n",
      "Epoch 9/100, Step: 46/338, Total Loss: 0.5894\n",
      "Epoch 9/100, Step: 96/338, Total Loss: 1.8586\n",
      "Epoch 9/100, Step: 146/338, Total Loss: 1.2036\n",
      "Epoch 9/100, Step: 196/338, Total Loss: 1.0226\n",
      "Epoch 9/100, Step: 246/338, Total Loss: 0.0963\n",
      "Epoch 9/100, Step: 296/338, Total Loss: 0.7795\n",
      "Epoch 9, accuracy: 0.9617, validation Loss: 0.0103\n",
      "\n",
      "Epoch 10/100, Step: 8/338, Total Loss: 0.4939\n",
      "Epoch 10/100, Step: 58/338, Total Loss: 0.1380\n",
      "Epoch 10/100, Step: 108/338, Total Loss: 0.9778\n",
      "Epoch 10/100, Step: 158/338, Total Loss: 0.3882\n",
      "Epoch 10/100, Step: 208/338, Total Loss: 0.8264\n",
      "Epoch 10/100, Step: 258/338, Total Loss: 0.2346\n",
      "Epoch 10/100, Step: 308/338, Total Loss: 1.7227\n",
      "Epoch 10, accuracy: 0.9633, validation Loss: 0.0118\n",
      "\n",
      "Epoch 11/100, Step: 20/338, Total Loss: 0.2920\n",
      "Epoch 11/100, Step: 70/338, Total Loss: 0.1081\n",
      "Epoch 11/100, Step: 120/338, Total Loss: 0.0350\n",
      "Epoch 11/100, Step: 170/338, Total Loss: 0.0362\n",
      "Epoch 11/100, Step: 220/338, Total Loss: 0.0262\n",
      "Epoch 11/100, Step: 270/338, Total Loss: 0.0376\n",
      "Epoch 11/100, Step: 320/338, Total Loss: 0.0152\n",
      "Epoch 11, accuracy: 0.9650, validation Loss: 0.0156\n",
      "\n",
      "Epoch 12/100, Step: 32/338, Total Loss: 0.0121\n",
      "Epoch 12/100, Step: 82/338, Total Loss: 0.0119\n",
      "Epoch 12/100, Step: 132/338, Total Loss: 0.0132\n",
      "Epoch 12/100, Step: 182/338, Total Loss: 0.0105\n",
      "Epoch 12/100, Step: 232/338, Total Loss: 0.0102\n",
      "Epoch 12/100, Step: 282/338, Total Loss: 0.0085\n",
      "Epoch 12/100, Step: 332/338, Total Loss: 0.0087\n",
      "Epoch 12, accuracy: 0.9667, validation Loss: 0.0164\n",
      "\n",
      "Epoch 13/100, Step: 44/338, Total Loss: 0.0073\n",
      "Epoch 13/100, Step: 94/338, Total Loss: 0.0086\n",
      "Epoch 13/100, Step: 144/338, Total Loss: 0.0069\n",
      "Epoch 13/100, Step: 194/338, Total Loss: 0.0067\n",
      "Epoch 13/100, Step: 244/338, Total Loss: 0.0067\n",
      "Epoch 13/100, Step: 294/338, Total Loss: 1.7629\n",
      "Epoch 13, accuracy: 0.9583, validation Loss: 0.0128\n",
      "\n",
      "Epoch 14/100, Step: 6/338, Total Loss: 1.3846\n",
      "Epoch 14/100, Step: 56/338, Total Loss: 1.6387\n",
      "Epoch 14/100, Step: 106/338, Total Loss: 0.2143\n",
      "Epoch 14/100, Step: 156/338, Total Loss: 0.1419\n",
      "Epoch 14/100, Step: 206/338, Total Loss: 1.2885\n",
      "Epoch 14/100, Step: 256/338, Total Loss: 0.7250\n",
      "Epoch 14/100, Step: 306/338, Total Loss: 1.9098\n",
      "Epoch 14, accuracy: 0.9500, validation Loss: 0.0113\n",
      "\n",
      "Epoch 15/100, Step: 18/338, Total Loss: 0.6337\n",
      "Epoch 15/100, Step: 68/338, Total Loss: 0.4276\n",
      "Epoch 15/100, Step: 118/338, Total Loss: 0.3663\n",
      "Epoch 15/100, Step: 168/338, Total Loss: 0.1279\n",
      "Epoch 15/100, Step: 218/338, Total Loss: 0.7577\n",
      "Epoch 15/100, Step: 268/338, Total Loss: 0.2186\n",
      "Epoch 15/100, Step: 318/338, Total Loss: 0.4890\n",
      "Epoch 15, accuracy: 0.9583, validation Loss: 0.0126\n",
      "\n",
      "Epoch 16/100, Step: 30/338, Total Loss: 0.0939\n",
      "Epoch 16/100, Step: 80/338, Total Loss: 0.0538\n",
      "Epoch 16/100, Step: 130/338, Total Loss: 1.0881\n",
      "Epoch 16/100, Step: 180/338, Total Loss: 0.7200\n",
      "Epoch 16/100, Step: 230/338, Total Loss: 0.0711\n",
      "Epoch 16/100, Step: 280/338, Total Loss: 0.4711\n",
      "Epoch 16/100, Step: 330/338, Total Loss: 0.1417\n",
      "Epoch 16, accuracy: 0.9617, validation Loss: 0.0144\n",
      "\n",
      "Epoch 17/100, Step: 42/338, Total Loss: 0.0184\n",
      "Epoch 17/100, Step: 92/338, Total Loss: 0.5107\n",
      "Epoch 17/100, Step: 142/338, Total Loss: 0.0624\n",
      "Epoch 17/100, Step: 192/338, Total Loss: 0.8765\n",
      "Epoch 17/100, Step: 242/338, Total Loss: 0.4695\n",
      "Epoch 17/100, Step: 292/338, Total Loss: 0.0291\n",
      "Epoch 17, accuracy: 0.9600, validation Loss: 0.0155\n",
      "\n",
      "Epoch 18/100, Step: 4/338, Total Loss: 0.1017\n",
      "Epoch 18/100, Step: 54/338, Total Loss: 0.2860\n",
      "Epoch 18/100, Step: 104/338, Total Loss: 0.1212\n",
      "Epoch 18/100, Step: 154/338, Total Loss: 0.0109\n",
      "Epoch 18/100, Step: 204/338, Total Loss: 0.4083\n",
      "Epoch 18/100, Step: 254/338, Total Loss: 0.0840\n",
      "Epoch 18/100, Step: 304/338, Total Loss: 0.1575\n",
      "Epoch 18, accuracy: 0.9617, validation Loss: 0.0163\n",
      "\n",
      "Epoch 19/100, Step: 16/338, Total Loss: 0.1045\n",
      "Epoch 19/100, Step: 66/338, Total Loss: 0.0080\n",
      "Epoch 19/100, Step: 116/338, Total Loss: 0.0114\n",
      "Epoch 19/100, Step: 166/338, Total Loss: 0.0072\n",
      "Epoch 19/100, Step: 216/338, Total Loss: 0.3706\n",
      "Epoch 19/100, Step: 266/338, Total Loss: 0.1217\n",
      "Epoch 19/100, Step: 316/338, Total Loss: 0.5524\n",
      "Epoch 19, accuracy: 0.9617, validation Loss: 0.0163\n",
      "\n",
      "Epoch 20/100, Step: 28/338, Total Loss: 0.0310\n",
      "Epoch 20/100, Step: 78/338, Total Loss: 0.0080\n",
      "Epoch 20/100, Step: 128/338, Total Loss: 0.0074\n",
      "Epoch 20/100, Step: 178/338, Total Loss: 0.0071\n",
      "Epoch 20/100, Step: 228/338, Total Loss: 0.0069\n",
      "Epoch 20/100, Step: 278/338, Total Loss: 0.0058\n",
      "Epoch 20/100, Step: 328/338, Total Loss: 0.0055\n",
      "Epoch 20, accuracy: 0.9583, validation Loss: 0.0190\n",
      "\n",
      "Epoch 21/100, Step: 40/338, Total Loss: 0.0046\n",
      "Epoch 21/100, Step: 90/338, Total Loss: 0.0044\n",
      "Epoch 21/100, Step: 140/338, Total Loss: 0.0041\n",
      "Epoch 21/100, Step: 190/338, Total Loss: 0.0043\n",
      "Epoch 21/100, Step: 240/338, Total Loss: 0.0038\n",
      "Epoch 21/100, Step: 290/338, Total Loss: 0.0037\n",
      "Epoch 21, accuracy: 0.9583, validation Loss: 0.0188\n",
      "\n",
      "Epoch 22/100, Step: 2/338, Total Loss: 0.0033\n",
      "Epoch 22/100, Step: 52/338, Total Loss: 0.0032\n",
      "Epoch 22/100, Step: 102/338, Total Loss: 0.0031\n",
      "Epoch 22/100, Step: 152/338, Total Loss: 0.0030\n",
      "Epoch 22/100, Step: 202/338, Total Loss: 0.0030\n",
      "Epoch 22/100, Step: 252/338, Total Loss: 0.0036\n",
      "Epoch 22/100, Step: 302/338, Total Loss: 0.0027\n",
      "Epoch 22, accuracy: 0.9600, validation Loss: 0.0208\n",
      "\n",
      "Epoch 23/100, Step: 14/338, Total Loss: 0.0044\n",
      "Epoch 23/100, Step: 64/338, Total Loss: 0.0024\n",
      "Epoch 23/100, Step: 114/338, Total Loss: 0.0022\n",
      "Epoch 23/100, Step: 164/338, Total Loss: 0.0027\n",
      "Epoch 23/100, Step: 214/338, Total Loss: 0.0022\n",
      "Epoch 23/100, Step: 264/338, Total Loss: 0.0020\n",
      "Epoch 23/100, Step: 314/338, Total Loss: 0.0020\n",
      "Epoch 23, accuracy: 0.9600, validation Loss: 0.0214\n",
      "\n",
      "Epoch 24/100, Step: 26/338, Total Loss: 0.0019\n",
      "Epoch 24/100, Step: 76/338, Total Loss: 0.0019\n",
      "Epoch 24/100, Step: 126/338, Total Loss: 0.0018\n",
      "Epoch 24/100, Step: 176/338, Total Loss: 0.0017\n",
      "Epoch 24/100, Step: 226/338, Total Loss: 0.0016\n",
      "Epoch 24/100, Step: 276/338, Total Loss: 0.0016\n",
      "Epoch 24/100, Step: 326/338, Total Loss: 0.0016\n",
      "Epoch 24, accuracy: 0.9600, validation Loss: 0.0242\n",
      "\n",
      "Epoch 25/100, Step: 38/338, Total Loss: 0.0015\n",
      "Epoch 25/100, Step: 88/338, Total Loss: 0.0014\n",
      "Epoch 25/100, Step: 138/338, Total Loss: 0.0014\n",
      "Epoch 25/100, Step: 188/338, Total Loss: 0.0014\n",
      "Epoch 25/100, Step: 238/338, Total Loss: 0.0014\n",
      "Epoch 25/100, Step: 288/338, Total Loss: 0.0013\n",
      "Epoch 25/100, Step: 338/338, Total Loss: 0.0012\n",
      "Epoch 25, accuracy: 0.9600, validation Loss: 0.0223\n",
      "\n",
      "Epoch 26/100, Step: 50/338, Total Loss: 0.0012\n",
      "Epoch 26/100, Step: 100/338, Total Loss: 0.0012\n",
      "Epoch 26/100, Step: 150/338, Total Loss: 0.0011\n",
      "Epoch 26/100, Step: 200/338, Total Loss: 0.0012\n",
      "Epoch 26/100, Step: 250/338, Total Loss: 0.0011\n",
      "Epoch 26/100, Step: 300/338, Total Loss: 0.0010\n",
      "Epoch 26, accuracy: 0.9600, validation Loss: 0.0231\n",
      "\n",
      "Epoch 27/100, Step: 12/338, Total Loss: 0.0010\n",
      "Epoch 27/100, Step: 62/338, Total Loss: 0.0010\n",
      "Epoch 27/100, Step: 112/338, Total Loss: 0.0009\n",
      "Epoch 27/100, Step: 162/338, Total Loss: 0.0009\n",
      "Epoch 27/100, Step: 212/338, Total Loss: 0.0009\n",
      "Epoch 27/100, Step: 262/338, Total Loss: 0.0009\n",
      "Epoch 27/100, Step: 312/338, Total Loss: 0.0008\n",
      "Epoch 27, accuracy: 0.9600, validation Loss: 0.0244\n",
      "\n",
      "Epoch 28/100, Step: 24/338, Total Loss: 0.0008\n",
      "Epoch 28/100, Step: 74/338, Total Loss: 0.0008\n",
      "Epoch 28/100, Step: 124/338, Total Loss: 0.0008\n",
      "Epoch 28/100, Step: 174/338, Total Loss: 0.0007\n",
      "Epoch 28/100, Step: 224/338, Total Loss: 0.0008\n",
      "Epoch 28/100, Step: 274/338, Total Loss: 0.0007\n",
      "Epoch 28/100, Step: 324/338, Total Loss: 0.0007\n",
      "Epoch 28, accuracy: 0.9600, validation Loss: 0.0237\n",
      "\n",
      "Epoch 29/100, Step: 36/338, Total Loss: 0.0007\n",
      "Epoch 29/100, Step: 86/338, Total Loss: 0.0006\n",
      "Epoch 29/100, Step: 136/338, Total Loss: 0.0006\n",
      "Epoch 29/100, Step: 186/338, Total Loss: 0.0006\n",
      "Epoch 29/100, Step: 236/338, Total Loss: 0.0006\n",
      "Epoch 29/100, Step: 286/338, Total Loss: 0.0006\n",
      "Epoch 29/100, Step: 336/338, Total Loss: 0.0006\n",
      "Epoch 29, accuracy: 0.9600, validation Loss: 0.0242\n",
      "\n",
      "Epoch 30/100, Step: 48/338, Total Loss: 0.0005\n",
      "Epoch 30/100, Step: 98/338, Total Loss: 0.0005\n",
      "Epoch 30/100, Step: 148/338, Total Loss: 0.0005\n",
      "Epoch 30/100, Step: 198/338, Total Loss: 0.0005\n",
      "Epoch 30/100, Step: 248/338, Total Loss: 0.0005\n",
      "Epoch 30/100, Step: 298/338, Total Loss: 0.0005\n",
      "Epoch 30, accuracy: 0.9600, validation Loss: 0.0246\n",
      "\n",
      "Epoch 31/100, Step: 10/338, Total Loss: 0.0005\n",
      "Epoch 31/100, Step: 60/338, Total Loss: 0.0005\n",
      "Epoch 31/100, Step: 110/338, Total Loss: 0.0004\n",
      "Epoch 31/100, Step: 160/338, Total Loss: 0.0004\n",
      "Epoch 31/100, Step: 210/338, Total Loss: 0.0004\n",
      "Epoch 31/100, Step: 260/338, Total Loss: 0.0004\n",
      "Epoch 31/100, Step: 310/338, Total Loss: 0.0004\n",
      "Epoch 31, accuracy: 0.9600, validation Loss: 0.0250\n",
      "\n",
      "Epoch 32/100, Step: 22/338, Total Loss: 0.0004\n",
      "Epoch 32/100, Step: 72/338, Total Loss: 0.0004\n",
      "Epoch 32/100, Step: 122/338, Total Loss: 0.0004\n",
      "Epoch 32/100, Step: 172/338, Total Loss: 0.0003\n",
      "Epoch 32/100, Step: 222/338, Total Loss: 0.0003\n",
      "Epoch 32/100, Step: 272/338, Total Loss: 0.0003\n",
      "Epoch 32/100, Step: 322/338, Total Loss: 0.0003\n",
      "Epoch 32, accuracy: 0.9600, validation Loss: 0.0255\n",
      "\n",
      "Epoch 33/100, Step: 34/338, Total Loss: 0.0003\n",
      "Epoch 33/100, Step: 84/338, Total Loss: 0.0003\n",
      "Epoch 33/100, Step: 134/338, Total Loss: 0.0003\n",
      "Epoch 33/100, Step: 184/338, Total Loss: 0.0003\n",
      "Epoch 33/100, Step: 234/338, Total Loss: 0.0003\n",
      "Epoch 33/100, Step: 284/338, Total Loss: 0.0003\n",
      "Epoch 33/100, Step: 334/338, Total Loss: 0.0003\n",
      "Epoch 33, accuracy: 0.9600, validation Loss: 0.0264\n",
      "\n",
      "Epoch 34/100, Step: 46/338, Total Loss: 0.0003\n",
      "Epoch 34/100, Step: 96/338, Total Loss: 0.0003\n",
      "Epoch 34/100, Step: 146/338, Total Loss: 0.0002\n",
      "Epoch 34/100, Step: 196/338, Total Loss: 0.0002\n",
      "Epoch 34/100, Step: 246/338, Total Loss: 0.0002\n",
      "Epoch 34/100, Step: 296/338, Total Loss: 0.0002\n",
      "Epoch 34, accuracy: 0.9600, validation Loss: 0.0268\n",
      "\n",
      "Epoch 35/100, Step: 8/338, Total Loss: 0.0002\n",
      "Epoch 35/100, Step: 58/338, Total Loss: 0.0002\n",
      "Epoch 35/100, Step: 108/338, Total Loss: 0.0002\n",
      "Epoch 35/100, Step: 158/338, Total Loss: 0.0002\n",
      "Epoch 35/100, Step: 208/338, Total Loss: 0.0002\n",
      "Epoch 35/100, Step: 258/338, Total Loss: 0.0002\n",
      "Epoch 35/100, Step: 308/338, Total Loss: 0.0002\n",
      "Epoch 35, accuracy: 0.9600, validation Loss: 0.0299\n",
      "\n",
      "Epoch 36/100, Step: 20/338, Total Loss: 0.0002\n",
      "Epoch 36/100, Step: 70/338, Total Loss: 0.0002\n",
      "Epoch 36/100, Step: 120/338, Total Loss: 0.0002\n",
      "Epoch 36/100, Step: 170/338, Total Loss: 0.0002\n",
      "Epoch 36/100, Step: 220/338, Total Loss: 0.0002\n",
      "Epoch 36/100, Step: 270/338, Total Loss: 0.0002\n",
      "Epoch 36/100, Step: 320/338, Total Loss: 0.0002\n",
      "Epoch 36, accuracy: 0.9583, validation Loss: 0.0273\n",
      "\n",
      "Epoch 37/100, Step: 32/338, Total Loss: 0.0001\n",
      "Epoch 37/100, Step: 82/338, Total Loss: 0.0001\n",
      "Epoch 37/100, Step: 132/338, Total Loss: 0.0001\n",
      "Epoch 37/100, Step: 182/338, Total Loss: 0.0001\n",
      "Epoch 37/100, Step: 232/338, Total Loss: 0.0001\n",
      "Epoch 37/100, Step: 282/338, Total Loss: 0.0001\n",
      "Epoch 37/100, Step: 332/338, Total Loss: 0.0001\n",
      "Epoch 37, accuracy: 0.9583, validation Loss: 0.0290\n",
      "\n",
      "Epoch 38/100, Step: 44/338, Total Loss: 0.0001\n",
      "Epoch 38/100, Step: 94/338, Total Loss: 0.0001\n",
      "Epoch 38/100, Step: 144/338, Total Loss: 0.0001\n",
      "Epoch 38/100, Step: 194/338, Total Loss: 0.0001\n",
      "Epoch 38/100, Step: 244/338, Total Loss: 0.0001\n",
      "Epoch 38/100, Step: 294/338, Total Loss: 0.0001\n",
      "Epoch 38, accuracy: 0.9583, validation Loss: 0.0281\n",
      "\n",
      "Epoch 39/100, Step: 6/338, Total Loss: 0.0001\n",
      "Epoch 39/100, Step: 56/338, Total Loss: 0.0001\n",
      "Epoch 39/100, Step: 106/338, Total Loss: 0.0001\n",
      "Epoch 39/100, Step: 156/338, Total Loss: 0.0001\n",
      "Epoch 39/100, Step: 206/338, Total Loss: 0.0001\n",
      "Epoch 39/100, Step: 256/338, Total Loss: 0.0001\n",
      "Epoch 39/100, Step: 306/338, Total Loss: 0.0001\n",
      "Epoch 39, accuracy: 0.9583, validation Loss: 0.0299\n",
      "\n",
      "Epoch 40/100, Step: 18/338, Total Loss: 0.0001\n",
      "Epoch 40/100, Step: 68/338, Total Loss: 0.0001\n",
      "Epoch 40/100, Step: 118/338, Total Loss: 0.0001\n",
      "Epoch 40/100, Step: 168/338, Total Loss: 0.0001\n",
      "Epoch 40/100, Step: 218/338, Total Loss: 0.0001\n",
      "Epoch 40/100, Step: 268/338, Total Loss: 0.0001\n",
      "Epoch 40/100, Step: 318/338, Total Loss: 0.0001\n",
      "Epoch 40, accuracy: 0.9583, validation Loss: 0.0289\n",
      "\n",
      "Epoch 41/100, Step: 30/338, Total Loss: 0.0001\n",
      "Epoch 41/100, Step: 80/338, Total Loss: 0.0001\n",
      "Epoch 41/100, Step: 130/338, Total Loss: 0.0001\n",
      "Epoch 41/100, Step: 180/338, Total Loss: 0.0001\n",
      "Epoch 41/100, Step: 230/338, Total Loss: 0.0001\n",
      "Epoch 41/100, Step: 280/338, Total Loss: 0.0001\n",
      "Epoch 41/100, Step: 330/338, Total Loss: 0.0001\n",
      "Epoch 41, accuracy: 0.9583, validation Loss: 0.0293\n",
      "\n",
      "Epoch 42/100, Step: 42/338, Total Loss: 0.0001\n",
      "Epoch 42/100, Step: 92/338, Total Loss: 0.0001\n",
      "Epoch 42/100, Step: 142/338, Total Loss: 0.0001\n",
      "Epoch 42/100, Step: 192/338, Total Loss: 0.0001\n",
      "Epoch 42/100, Step: 242/338, Total Loss: 0.0001\n",
      "Epoch 42/100, Step: 292/338, Total Loss: 0.0000\n",
      "Epoch 42, accuracy: 0.9583, validation Loss: 0.0297\n",
      "\n",
      "Epoch 43/100, Step: 4/338, Total Loss: 0.0000\n",
      "Epoch 43/100, Step: 54/338, Total Loss: 0.0001\n",
      "Epoch 43/100, Step: 104/338, Total Loss: 0.0000\n",
      "Epoch 43/100, Step: 154/338, Total Loss: 0.0000\n",
      "Epoch 43/100, Step: 204/338, Total Loss: 0.0000\n",
      "Epoch 43/100, Step: 254/338, Total Loss: 0.0000\n",
      "Epoch 43/100, Step: 304/338, Total Loss: 0.0000\n",
      "Epoch 43, accuracy: 0.9617, validation Loss: 0.0311\n",
      "\n",
      "Epoch 44/100, Step: 16/338, Total Loss: 0.0000\n",
      "Epoch 44/100, Step: 66/338, Total Loss: 0.0000\n",
      "Epoch 44/100, Step: 116/338, Total Loss: 0.0000\n",
      "Epoch 44/100, Step: 166/338, Total Loss: 0.0000\n",
      "Epoch 44/100, Step: 216/338, Total Loss: 0.0000\n",
      "Epoch 44/100, Step: 266/338, Total Loss: 0.0000\n",
      "Epoch 44/100, Step: 316/338, Total Loss: 0.0000\n",
      "Epoch 44, accuracy: 0.9617, validation Loss: 0.0301\n",
      "\n",
      "Epoch 45/100, Step: 28/338, Total Loss: 0.0000\n",
      "Epoch 45/100, Step: 78/338, Total Loss: 0.0000\n",
      "Epoch 45/100, Step: 128/338, Total Loss: 0.0000\n",
      "Epoch 45/100, Step: 178/338, Total Loss: 0.0000\n",
      "Epoch 45/100, Step: 228/338, Total Loss: 0.0000\n",
      "Epoch 45/100, Step: 278/338, Total Loss: 0.0000\n",
      "Epoch 45/100, Step: 328/338, Total Loss: 0.0000\n",
      "Epoch 45, accuracy: 0.9617, validation Loss: 0.0307\n",
      "\n",
      "Epoch 46/100, Step: 40/338, Total Loss: 0.0000\n",
      "Epoch 46/100, Step: 90/338, Total Loss: 0.0000\n",
      "Epoch 46/100, Step: 140/338, Total Loss: 0.0000\n",
      "Epoch 46/100, Step: 190/338, Total Loss: 0.0000\n",
      "Epoch 46/100, Step: 240/338, Total Loss: 0.0000\n",
      "Epoch 46/100, Step: 290/338, Total Loss: 0.0000\n",
      "Epoch 46, accuracy: 0.9617, validation Loss: 0.0341\n",
      "\n",
      "Epoch 47/100, Step: 2/338, Total Loss: 0.0000\n",
      "Epoch 47/100, Step: 52/338, Total Loss: 0.0000\n",
      "Epoch 47/100, Step: 102/338, Total Loss: 0.0000\n",
      "Epoch 47/100, Step: 152/338, Total Loss: 0.0000\n",
      "Epoch 47/100, Step: 202/338, Total Loss: 0.0000\n",
      "Epoch 47/100, Step: 252/338, Total Loss: 0.0000\n",
      "Epoch 47/100, Step: 302/338, Total Loss: 0.0000\n",
      "Epoch 47, accuracy: 0.9617, validation Loss: 0.0312\n",
      "\n",
      "Epoch 48/100, Step: 14/338, Total Loss: 0.0000\n",
      "Epoch 48/100, Step: 64/338, Total Loss: 0.0000\n",
      "Epoch 48/100, Step: 114/338, Total Loss: 0.0000\n",
      "Epoch 48/100, Step: 164/338, Total Loss: 0.0000\n",
      "Epoch 48/100, Step: 214/338, Total Loss: 0.0000\n",
      "Epoch 48/100, Step: 264/338, Total Loss: 0.0000\n",
      "Epoch 48/100, Step: 314/338, Total Loss: 0.0000\n",
      "Epoch 48, accuracy: 0.9617, validation Loss: 0.0321\n",
      "\n",
      "Epoch 49/100, Step: 26/338, Total Loss: 0.0000\n",
      "Epoch 49/100, Step: 76/338, Total Loss: 0.0000\n",
      "Epoch 49/100, Step: 126/338, Total Loss: 0.0000\n",
      "Epoch 49/100, Step: 176/338, Total Loss: 0.0000\n",
      "Epoch 49/100, Step: 226/338, Total Loss: 0.0000\n",
      "Epoch 49/100, Step: 276/338, Total Loss: 0.0000\n",
      "Epoch 49/100, Step: 326/338, Total Loss: 0.0000\n",
      "Epoch 49, accuracy: 0.9617, validation Loss: 0.0323\n",
      "\n",
      "Epoch 50/100, Step: 38/338, Total Loss: 0.0000\n",
      "Epoch 50/100, Step: 88/338, Total Loss: 0.0000\n",
      "Epoch 50/100, Step: 138/338, Total Loss: 0.0000\n",
      "Epoch 50/100, Step: 188/338, Total Loss: 0.0000\n",
      "Epoch 50/100, Step: 238/338, Total Loss: 0.0000\n",
      "Epoch 50/100, Step: 288/338, Total Loss: 0.0000\n",
      "Epoch 50/100, Step: 338/338, Total Loss: 0.0000\n",
      "Epoch 50, accuracy: 0.9600, validation Loss: 0.0329\n",
      "\n",
      "Epoch 51/100, Step: 50/338, Total Loss: 0.0000\n",
      "Epoch 51/100, Step: 100/338, Total Loss: 0.0000\n",
      "Epoch 51/100, Step: 150/338, Total Loss: 0.0000\n",
      "Epoch 51/100, Step: 200/338, Total Loss: 0.0000\n",
      "Epoch 51/100, Step: 250/338, Total Loss: 0.0000\n",
      "Epoch 51/100, Step: 300/338, Total Loss: 0.0000\n",
      "Epoch 51, accuracy: 0.9600, validation Loss: 0.0331\n",
      "\n",
      "Epoch 52/100, Step: 12/338, Total Loss: 0.0000\n",
      "Epoch 52/100, Step: 62/338, Total Loss: 0.0000\n",
      "Epoch 52/100, Step: 112/338, Total Loss: 0.0000\n",
      "Epoch 52/100, Step: 162/338, Total Loss: 0.0000\n",
      "Epoch 52/100, Step: 212/338, Total Loss: 0.0000\n",
      "Epoch 52/100, Step: 262/338, Total Loss: 0.0000\n",
      "Epoch 52/100, Step: 312/338, Total Loss: 0.0000\n",
      "Epoch 52, accuracy: 0.9600, validation Loss: 0.0332\n",
      "\n",
      "Epoch 53/100, Step: 24/338, Total Loss: 0.0000\n",
      "Epoch 53/100, Step: 74/338, Total Loss: 0.0000\n",
      "Epoch 53/100, Step: 124/338, Total Loss: 0.0000\n",
      "Epoch 53/100, Step: 174/338, Total Loss: 0.0000\n",
      "Epoch 53/100, Step: 224/338, Total Loss: 0.0000\n",
      "Epoch 53/100, Step: 274/338, Total Loss: 0.0000\n",
      "Epoch 53/100, Step: 324/338, Total Loss: 0.0000\n",
      "Epoch 53, accuracy: 0.9600, validation Loss: 0.1210\n",
      "\n",
      "Epoch 54/100, Step: 36/338, Total Loss: 0.0000\n",
      "Epoch 54/100, Step: 86/338, Total Loss: 0.0000\n",
      "Epoch 54/100, Step: 136/338, Total Loss: 0.0000\n",
      "Epoch 54/100, Step: 186/338, Total Loss: 0.0000\n",
      "Epoch 54/100, Step: 236/338, Total Loss: 0.0000\n",
      "Epoch 54/100, Step: 286/338, Total Loss: 0.0000\n",
      "Epoch 54/100, Step: 336/338, Total Loss: 0.0000\n",
      "Epoch 54, accuracy: 0.9600, validation Loss: 0.1212\n",
      "\n",
      "Epoch 55/100, Step: 48/338, Total Loss: 0.0000\n",
      "Epoch 55/100, Step: 98/338, Total Loss: 0.0000\n",
      "Epoch 55/100, Step: 148/338, Total Loss: 0.0000\n",
      "Epoch 55/100, Step: 198/338, Total Loss: 0.0000\n",
      "Epoch 55/100, Step: 248/338, Total Loss: 0.0000\n",
      "Epoch 55/100, Step: 298/338, Total Loss: 0.0000\n",
      "Epoch 55, accuracy: 0.9617, validation Loss: 0.1508\n",
      "\n",
      "Epoch 56/100, Step: 10/338, Total Loss: 0.0000\n",
      "Epoch 56/100, Step: 60/338, Total Loss: 0.0000\n",
      "Epoch 56/100, Step: 110/338, Total Loss: 0.0000\n",
      "Epoch 56/100, Step: 160/338, Total Loss: 0.0000\n",
      "Epoch 56/100, Step: 210/338, Total Loss: 0.0000\n",
      "Epoch 56/100, Step: 260/338, Total Loss: 0.0000\n",
      "Epoch 56/100, Step: 310/338, Total Loss: 0.0000\n",
      "Epoch 56, accuracy: 0.9617, validation Loss: 0.1301\n",
      "\n",
      "Epoch 57/100, Step: 22/338, Total Loss: 0.0000\n",
      "Epoch 57/100, Step: 72/338, Total Loss: 0.0000\n",
      "Epoch 57/100, Step: 122/338, Total Loss: 0.0000\n",
      "Epoch 57/100, Step: 172/338, Total Loss: 0.0000\n",
      "Epoch 57/100, Step: 222/338, Total Loss: 0.0000\n",
      "Epoch 57/100, Step: 272/338, Total Loss: 0.0000\n",
      "Epoch 57/100, Step: 322/338, Total Loss: 0.0000\n",
      "Epoch 57, accuracy: 0.9617, validation Loss: 0.1303\n",
      "\n",
      "Epoch 58/100, Step: 34/338, Total Loss: 0.0000\n",
      "Epoch 58/100, Step: 84/338, Total Loss: 0.0000\n",
      "Epoch 58/100, Step: 134/338, Total Loss: 0.0000\n",
      "Epoch 58/100, Step: 184/338, Total Loss: 0.0000\n",
      "Epoch 58/100, Step: 234/338, Total Loss: 0.0000\n",
      "Epoch 58/100, Step: 284/338, Total Loss: 0.0000\n",
      "Epoch 58/100, Step: 334/338, Total Loss: 0.0000\n",
      "Epoch 58, accuracy: 0.9600, validation Loss: 0.1305\n",
      "\n",
      "Epoch 59/100, Step: 46/338, Total Loss: 0.0000\n",
      "Epoch 59/100, Step: 96/338, Total Loss: 0.0000\n",
      "Epoch 59/100, Step: 146/338, Total Loss: 0.0000\n",
      "Epoch 59/100, Step: 196/338, Total Loss: 0.0000\n",
      "Epoch 59/100, Step: 246/338, Total Loss: 0.0000\n",
      "Epoch 59/100, Step: 296/338, Total Loss: 0.0000\n",
      "Epoch 59, accuracy: 0.9600, validation Loss: 0.1306\n",
      "\n",
      "Epoch 60/100, Step: 8/338, Total Loss: 0.0000\n",
      "Epoch 60/100, Step: 58/338, Total Loss: 0.0000\n",
      "Epoch 60/100, Step: 108/338, Total Loss: 0.0000\n",
      "Epoch 60/100, Step: 158/338, Total Loss: 0.0000\n",
      "Epoch 60/100, Step: 208/338, Total Loss: 0.0000\n",
      "Epoch 60/100, Step: 258/338, Total Loss: 0.0000\n",
      "Epoch 60/100, Step: 308/338, Total Loss: 0.0000\n",
      "Epoch 60, accuracy: 0.9600, validation Loss: 0.1308\n",
      "\n",
      "Epoch 61/100, Step: 20/338, Total Loss: 0.0000\n",
      "Epoch 61/100, Step: 70/338, Total Loss: 0.0000\n",
      "Epoch 61/100, Step: 120/338, Total Loss: 0.0000\n",
      "Epoch 61/100, Step: 170/338, Total Loss: 0.0000\n",
      "Epoch 61/100, Step: 220/338, Total Loss: 0.0000\n",
      "Epoch 61/100, Step: 270/338, Total Loss: 0.0000\n",
      "Epoch 61/100, Step: 320/338, Total Loss: 0.0000\n",
      "Epoch 61, accuracy: 0.9600, validation Loss: 0.1309\n",
      "\n",
      "Epoch 62/100, Step: 32/338, Total Loss: 0.0000\n",
      "Epoch 62/100, Step: 82/338, Total Loss: 0.0000\n",
      "Epoch 62/100, Step: 132/338, Total Loss: 0.0000\n",
      "Epoch 62/100, Step: 182/338, Total Loss: 0.0000\n",
      "Epoch 62/100, Step: 232/338, Total Loss: 0.0000\n",
      "Epoch 62/100, Step: 282/338, Total Loss: 0.0000\n",
      "Epoch 62/100, Step: 332/338, Total Loss: 0.0000\n",
      "Epoch 62, accuracy: 0.9600, validation Loss: 0.1323\n",
      "\n",
      "Epoch 63/100, Step: 44/338, Total Loss: 0.0000\n",
      "Epoch 63/100, Step: 94/338, Total Loss: 0.0000\n",
      "Epoch 63/100, Step: 144/338, Total Loss: 0.0000\n",
      "Epoch 63/100, Step: 194/338, Total Loss: 0.0000\n",
      "Epoch 63/100, Step: 244/338, Total Loss: 0.0000\n",
      "Epoch 63/100, Step: 294/338, Total Loss: 0.0000\n",
      "Epoch 63, accuracy: 0.9600, validation Loss: 0.1433\n",
      "\n",
      "Epoch 64/100, Step: 6/338, Total Loss: 0.0000\n",
      "Epoch 64/100, Step: 56/338, Total Loss: 0.0000\n",
      "Epoch 64/100, Step: 106/338, Total Loss: 0.0000\n",
      "Epoch 64/100, Step: 156/338, Total Loss: 0.0000\n",
      "Epoch 64/100, Step: 206/338, Total Loss: 0.0000\n",
      "Epoch 64/100, Step: 256/338, Total Loss: 0.0000\n",
      "Epoch 64/100, Step: 306/338, Total Loss: 0.0000\n",
      "Epoch 64, accuracy: 0.9617, validation Loss: 0.1333\n",
      "\n",
      "Epoch 65/100, Step: 18/338, Total Loss: 0.0000\n",
      "Epoch 65/100, Step: 68/338, Total Loss: 0.0000\n",
      "Epoch 65/100, Step: 118/338, Total Loss: 0.0000\n",
      "Epoch 65/100, Step: 168/338, Total Loss: 0.0000\n",
      "Epoch 65/100, Step: 218/338, Total Loss: 0.0000\n",
      "Epoch 65/100, Step: 268/338, Total Loss: 0.0000\n",
      "Epoch 65/100, Step: 318/338, Total Loss: 0.0000\n",
      "Epoch 65, accuracy: 0.9617, validation Loss: 0.1315\n",
      "\n",
      "Epoch 66/100, Step: 30/338, Total Loss: 0.0000\n",
      "Epoch 66/100, Step: 80/338, Total Loss: 0.0000\n",
      "Epoch 66/100, Step: 130/338, Total Loss: 0.0000\n",
      "Epoch 66/100, Step: 180/338, Total Loss: 0.0000\n",
      "Epoch 66/100, Step: 230/338, Total Loss: 0.0000\n",
      "Epoch 66/100, Step: 280/338, Total Loss: 0.0000\n",
      "Epoch 66/100, Step: 330/338, Total Loss: 0.0000\n",
      "Epoch 66, accuracy: 0.9617, validation Loss: 0.1317\n",
      "\n",
      "Epoch 67/100, Step: 42/338, Total Loss: 0.0000\n",
      "Epoch 67/100, Step: 92/338, Total Loss: 0.0000\n",
      "Epoch 67/100, Step: 142/338, Total Loss: 0.0000\n",
      "Epoch 67/100, Step: 192/338, Total Loss: 0.0000\n",
      "Epoch 67/100, Step: 242/338, Total Loss: 0.0000\n",
      "Epoch 67/100, Step: 292/338, Total Loss: 0.0000\n",
      "Epoch 67, accuracy: 0.9617, validation Loss: 0.1318\n",
      "\n",
      "Epoch 68/100, Step: 4/338, Total Loss: 0.0000\n",
      "Epoch 68/100, Step: 54/338, Total Loss: 0.0000\n",
      "Epoch 68/100, Step: 104/338, Total Loss: 0.0000\n",
      "Epoch 68/100, Step: 154/338, Total Loss: 0.0000\n",
      "Epoch 68/100, Step: 204/338, Total Loss: 0.0000\n",
      "Epoch 68/100, Step: 254/338, Total Loss: 0.0000\n",
      "Epoch 68/100, Step: 304/338, Total Loss: 0.0000\n",
      "Epoch 68, accuracy: 0.9617, validation Loss: 0.1319\n",
      "\n",
      "Epoch 69/100, Step: 16/338, Total Loss: 0.0000\n",
      "Epoch 69/100, Step: 66/338, Total Loss: 0.0000\n",
      "Epoch 69/100, Step: 116/338, Total Loss: 0.0000\n",
      "Epoch 69/100, Step: 166/338, Total Loss: 0.0000\n",
      "Epoch 69/100, Step: 216/338, Total Loss: 0.0000\n",
      "Epoch 69/100, Step: 266/338, Total Loss: 0.0000\n",
      "Epoch 69/100, Step: 316/338, Total Loss: 0.0000\n",
      "Epoch 69, accuracy: 0.9617, validation Loss: 0.1321\n",
      "\n",
      "Epoch 70/100, Step: 28/338, Total Loss: 0.0000\n",
      "Epoch 70/100, Step: 78/338, Total Loss: 0.0000\n",
      "Epoch 70/100, Step: 128/338, Total Loss: 0.0000\n",
      "Epoch 70/100, Step: 178/338, Total Loss: 0.0000\n",
      "Epoch 70/100, Step: 228/338, Total Loss: 0.0000\n",
      "Epoch 70/100, Step: 278/338, Total Loss: 0.0000\n",
      "Epoch 70/100, Step: 328/338, Total Loss: 0.0000\n",
      "Epoch 70, accuracy: 0.9617, validation Loss: 0.1322\n",
      "\n",
      "Epoch 71/100, Step: 40/338, Total Loss: 0.0000\n",
      "Epoch 71/100, Step: 90/338, Total Loss: 0.0000\n",
      "Epoch 71/100, Step: 140/338, Total Loss: 0.0000\n",
      "Epoch 71/100, Step: 190/338, Total Loss: 0.0000\n",
      "Epoch 71/100, Step: 240/338, Total Loss: 0.0000\n",
      "Epoch 71/100, Step: 290/338, Total Loss: 0.0000\n",
      "Epoch 71, accuracy: 0.9617, validation Loss: 0.1323\n",
      "\n",
      "Epoch 72/100, Step: 2/338, Total Loss: 0.0000\n",
      "Epoch 72/100, Step: 52/338, Total Loss: 0.0000\n",
      "Epoch 72/100, Step: 102/338, Total Loss: 0.0000\n",
      "Epoch 72/100, Step: 152/338, Total Loss: 0.0000\n",
      "Epoch 72/100, Step: 202/338, Total Loss: 0.0000\n",
      "Epoch 72/100, Step: 252/338, Total Loss: 0.0000\n",
      "Epoch 72/100, Step: 302/338, Total Loss: 0.0000\n",
      "Epoch 72, accuracy: 0.9617, validation Loss: 0.1428\n",
      "\n",
      "Epoch 73/100, Step: 14/338, Total Loss: 0.0000\n",
      "Epoch 73/100, Step: 64/338, Total Loss: 0.0000\n",
      "Epoch 73/100, Step: 114/338, Total Loss: 0.0000\n",
      "Epoch 73/100, Step: 164/338, Total Loss: 0.0000\n",
      "Epoch 73/100, Step: 214/338, Total Loss: 0.0000\n",
      "Epoch 73/100, Step: 264/338, Total Loss: 0.0000\n",
      "Epoch 73/100, Step: 314/338, Total Loss: 0.0000\n",
      "Epoch 73, accuracy: 0.9617, validation Loss: 0.1413\n",
      "\n",
      "Epoch 74/100, Step: 26/338, Total Loss: 0.0000\n",
      "Epoch 74/100, Step: 76/338, Total Loss: 0.0000\n",
      "Epoch 74/100, Step: 126/338, Total Loss: 0.0000\n",
      "Epoch 74/100, Step: 176/338, Total Loss: 0.0000\n",
      "Epoch 74/100, Step: 226/338, Total Loss: 0.0000\n",
      "Epoch 74/100, Step: 276/338, Total Loss: 0.0000\n",
      "Epoch 74/100, Step: 326/338, Total Loss: 0.0000\n",
      "Epoch 74, accuracy: 0.9617, validation Loss: 0.1414\n",
      "\n",
      "Epoch 75/100, Step: 38/338, Total Loss: 0.0000\n",
      "Epoch 75/100, Step: 88/338, Total Loss: 0.0000\n",
      "Epoch 75/100, Step: 138/338, Total Loss: 0.0000\n",
      "Epoch 75/100, Step: 188/338, Total Loss: 0.0000\n",
      "Epoch 75/100, Step: 238/338, Total Loss: 0.0000\n",
      "Epoch 75/100, Step: 288/338, Total Loss: 0.0000\n",
      "Epoch 75/100, Step: 338/338, Total Loss: 0.0000\n",
      "Epoch 75, accuracy: 0.9583, validation Loss: 0.1439\n",
      "\n",
      "Epoch 76/100, Step: 50/338, Total Loss: 0.0000\n",
      "Epoch 76/100, Step: 100/338, Total Loss: 0.0000\n",
      "Epoch 76/100, Step: 150/338, Total Loss: 0.0000\n",
      "Epoch 76/100, Step: 200/338, Total Loss: 0.0000\n",
      "Epoch 76/100, Step: 250/338, Total Loss: 0.0000\n",
      "Epoch 76/100, Step: 300/338, Total Loss: 0.0000\n",
      "Epoch 76, accuracy: 0.9583, validation Loss: 0.1336\n",
      "\n",
      "Epoch 77/100, Step: 12/338, Total Loss: 0.0000\n",
      "Epoch 77/100, Step: 62/338, Total Loss: 0.0000\n",
      "Epoch 77/100, Step: 112/338, Total Loss: 0.0000\n",
      "Epoch 77/100, Step: 162/338, Total Loss: 0.0000\n",
      "Epoch 77/100, Step: 212/338, Total Loss: 0.0000\n",
      "Epoch 77/100, Step: 262/338, Total Loss: 0.0000\n",
      "Epoch 77/100, Step: 312/338, Total Loss: 0.0000\n",
      "Epoch 77, accuracy: 0.9583, validation Loss: 0.1441\n",
      "\n",
      "Epoch 78/100, Step: 24/338, Total Loss: 0.0000\n",
      "Epoch 78/100, Step: 74/338, Total Loss: 0.0000\n",
      "Epoch 78/100, Step: 124/338, Total Loss: 0.0000\n",
      "Epoch 78/100, Step: 174/338, Total Loss: 0.0000\n",
      "Epoch 78/100, Step: 224/338, Total Loss: 0.0000\n",
      "Epoch 78/100, Step: 274/338, Total Loss: 0.0000\n",
      "Epoch 78/100, Step: 324/338, Total Loss: 0.0000\n",
      "Epoch 78, accuracy: 0.9583, validation Loss: 0.1425\n",
      "\n",
      "Epoch 79/100, Step: 36/338, Total Loss: 0.0000\n",
      "Epoch 79/100, Step: 86/338, Total Loss: 0.0000\n",
      "Epoch 79/100, Step: 136/338, Total Loss: 0.0000\n",
      "Epoch 79/100, Step: 186/338, Total Loss: 0.0000\n",
      "Epoch 79/100, Step: 236/338, Total Loss: 0.0000\n",
      "Epoch 79/100, Step: 286/338, Total Loss: 0.0000\n",
      "Epoch 79/100, Step: 336/338, Total Loss: 0.0000\n",
      "Epoch 79, accuracy: 0.9583, validation Loss: 0.1426\n",
      "\n",
      "Epoch 80/100, Step: 48/338, Total Loss: 0.0000\n",
      "Epoch 80/100, Step: 98/338, Total Loss: 0.0000\n",
      "Epoch 80/100, Step: 148/338, Total Loss: 0.0000\n",
      "Epoch 80/100, Step: 198/338, Total Loss: 0.0000\n",
      "Epoch 80/100, Step: 248/338, Total Loss: 0.0000\n",
      "Epoch 80/100, Step: 298/338, Total Loss: 0.0000\n",
      "Epoch 80, accuracy: 0.9583, validation Loss: 0.1449\n",
      "\n",
      "Epoch 81/100, Step: 10/338, Total Loss: 0.0000\n",
      "Epoch 81/100, Step: 60/338, Total Loss: 0.0000\n",
      "Epoch 81/100, Step: 110/338, Total Loss: 0.0000\n",
      "Epoch 81/100, Step: 160/338, Total Loss: 0.0000\n",
      "Epoch 81/100, Step: 210/338, Total Loss: 0.0000\n",
      "Epoch 81/100, Step: 260/338, Total Loss: 0.0000\n",
      "Epoch 81/100, Step: 310/338, Total Loss: 0.0000\n",
      "Epoch 81, accuracy: 0.9583, validation Loss: 0.1427\n",
      "\n",
      "Epoch 82/100, Step: 22/338, Total Loss: 0.0000\n",
      "Epoch 82/100, Step: 72/338, Total Loss: 0.0000\n",
      "Epoch 82/100, Step: 122/338, Total Loss: 0.0000\n",
      "Epoch 82/100, Step: 172/338, Total Loss: 0.0000\n",
      "Epoch 82/100, Step: 222/338, Total Loss: 0.0000\n",
      "Epoch 82/100, Step: 272/338, Total Loss: 0.0000\n",
      "Epoch 82/100, Step: 322/338, Total Loss: 0.0000\n",
      "Epoch 82, accuracy: 0.9583, validation Loss: 0.1428\n",
      "\n",
      "Epoch 83/100, Step: 34/338, Total Loss: 0.0000\n",
      "Epoch 83/100, Step: 84/338, Total Loss: 0.0000\n",
      "Epoch 83/100, Step: 134/338, Total Loss: 0.0000\n",
      "Epoch 83/100, Step: 184/338, Total Loss: 0.0000\n",
      "Epoch 83/100, Step: 234/338, Total Loss: 0.0000\n",
      "Epoch 83/100, Step: 284/338, Total Loss: 0.0000\n",
      "Epoch 83/100, Step: 334/338, Total Loss: 0.0000\n",
      "Epoch 83, accuracy: 0.9617, validation Loss: 0.1428\n",
      "\n",
      "Epoch 84/100, Step: 46/338, Total Loss: 0.0000\n",
      "Epoch 84/100, Step: 96/338, Total Loss: 0.0000\n",
      "Epoch 84/100, Step: 146/338, Total Loss: 0.0000\n",
      "Epoch 84/100, Step: 196/338, Total Loss: 0.0000\n",
      "Epoch 84/100, Step: 246/338, Total Loss: 0.0000\n",
      "Epoch 84/100, Step: 296/338, Total Loss: 0.0000\n",
      "Epoch 84, accuracy: 0.9617, validation Loss: 0.1443\n",
      "\n",
      "Epoch 85/100, Step: 8/338, Total Loss: 0.0000\n",
      "Epoch 85/100, Step: 58/338, Total Loss: 0.0000\n",
      "Epoch 85/100, Step: 108/338, Total Loss: 0.0000\n",
      "Epoch 85/100, Step: 158/338, Total Loss: 0.0000\n",
      "Epoch 85/100, Step: 208/338, Total Loss: 0.0000\n",
      "Epoch 85/100, Step: 258/338, Total Loss: 0.0000\n",
      "Epoch 85/100, Step: 308/338, Total Loss: 0.0000\n",
      "Epoch 85, accuracy: 0.9617, validation Loss: 0.1429\n",
      "\n",
      "Epoch 86/100, Step: 20/338, Total Loss: 0.0000\n",
      "Epoch 86/100, Step: 70/338, Total Loss: 0.0000\n",
      "Epoch 86/100, Step: 120/338, Total Loss: 0.0000\n",
      "Epoch 86/100, Step: 170/338, Total Loss: 0.0000\n",
      "Epoch 86/100, Step: 220/338, Total Loss: 0.0000\n",
      "Epoch 86/100, Step: 270/338, Total Loss: 0.0000\n",
      "Epoch 86/100, Step: 320/338, Total Loss: 0.0000\n",
      "Epoch 86, accuracy: 0.9617, validation Loss: 0.1452\n",
      "\n",
      "Epoch 87/100, Step: 32/338, Total Loss: 0.0000\n",
      "Epoch 87/100, Step: 82/338, Total Loss: 0.0000\n",
      "Epoch 87/100, Step: 132/338, Total Loss: 0.0000\n",
      "Epoch 87/100, Step: 182/338, Total Loss: 0.0000\n",
      "Epoch 87/100, Step: 232/338, Total Loss: 0.0000\n",
      "Epoch 87/100, Step: 282/338, Total Loss: 0.0000\n",
      "Epoch 87/100, Step: 332/338, Total Loss: 0.0000\n",
      "Epoch 87, accuracy: 0.9617, validation Loss: 0.1430\n",
      "\n",
      "Epoch 88/100, Step: 44/338, Total Loss: 0.0000\n",
      "Epoch 88/100, Step: 94/338, Total Loss: 0.0000\n",
      "Epoch 88/100, Step: 144/338, Total Loss: 0.0000\n",
      "Epoch 88/100, Step: 194/338, Total Loss: 0.0000\n",
      "Epoch 88/100, Step: 244/338, Total Loss: 0.0000\n",
      "Epoch 88/100, Step: 294/338, Total Loss: 0.0000\n",
      "Epoch 88, accuracy: 0.9617, validation Loss: 0.1535\n",
      "\n",
      "Epoch 89/100, Step: 6/338, Total Loss: 0.0000\n",
      "Epoch 89/100, Step: 56/338, Total Loss: 0.0000\n",
      "Epoch 89/100, Step: 106/338, Total Loss: 0.0000\n",
      "Epoch 89/100, Step: 156/338, Total Loss: 0.0000\n",
      "Epoch 89/100, Step: 206/338, Total Loss: 0.0000\n",
      "Epoch 89/100, Step: 256/338, Total Loss: 0.0000\n",
      "Epoch 89/100, Step: 306/338, Total Loss: 0.0000\n",
      "Epoch 89, accuracy: 0.9617, validation Loss: 0.1432\n",
      "\n",
      "Epoch 90/100, Step: 18/338, Total Loss: 0.0000\n",
      "Epoch 90/100, Step: 68/338, Total Loss: 0.0000\n",
      "Epoch 90/100, Step: 118/338, Total Loss: 0.0000\n",
      "Epoch 90/100, Step: 168/338, Total Loss: 0.0000\n",
      "Epoch 90/100, Step: 218/338, Total Loss: 0.0000\n",
      "Epoch 90/100, Step: 268/338, Total Loss: 0.0000\n",
      "Epoch 90/100, Step: 318/338, Total Loss: 0.0000\n",
      "Epoch 90, accuracy: 0.9617, validation Loss: 0.1431\n",
      "\n",
      "Epoch 91/100, Step: 30/338, Total Loss: 0.0000\n",
      "Epoch 91/100, Step: 80/338, Total Loss: 0.0000\n",
      "Epoch 91/100, Step: 130/338, Total Loss: 0.0000\n",
      "Epoch 91/100, Step: 180/338, Total Loss: 0.0000\n",
      "Epoch 91/100, Step: 230/338, Total Loss: 0.0000\n",
      "Epoch 91/100, Step: 280/338, Total Loss: 0.0000\n",
      "Epoch 91/100, Step: 330/338, Total Loss: 0.0000\n",
      "Epoch 91, accuracy: 0.9617, validation Loss: 0.1432\n",
      "\n",
      "Epoch 92/100, Step: 42/338, Total Loss: 0.0000\n",
      "Epoch 92/100, Step: 92/338, Total Loss: 0.0000\n",
      "Epoch 92/100, Step: 142/338, Total Loss: 0.0000\n",
      "Epoch 92/100, Step: 192/338, Total Loss: 0.0000\n",
      "Epoch 92/100, Step: 242/338, Total Loss: 0.0000\n",
      "Epoch 92/100, Step: 292/338, Total Loss: 0.0000\n",
      "Epoch 92, accuracy: 0.9617, validation Loss: 0.1433\n",
      "\n",
      "Epoch 93/100, Step: 4/338, Total Loss: 0.0000\n",
      "Epoch 93/100, Step: 54/338, Total Loss: 0.0000\n",
      "Epoch 93/100, Step: 104/338, Total Loss: 0.0000\n",
      "Epoch 93/100, Step: 154/338, Total Loss: 0.0000\n",
      "Epoch 93/100, Step: 204/338, Total Loss: 0.0000\n",
      "Epoch 93/100, Step: 254/338, Total Loss: 0.0000\n",
      "Epoch 93/100, Step: 304/338, Total Loss: 0.0000\n",
      "Epoch 93, accuracy: 0.9617, validation Loss: 0.1433\n",
      "\n",
      "Epoch 94/100, Step: 16/338, Total Loss: 0.0000\n",
      "Epoch 94/100, Step: 66/338, Total Loss: 0.0000\n",
      "Epoch 94/100, Step: 116/338, Total Loss: 0.0000\n",
      "Epoch 94/100, Step: 166/338, Total Loss: 0.0000\n",
      "Epoch 94/100, Step: 216/338, Total Loss: 0.0000\n",
      "Epoch 94/100, Step: 266/338, Total Loss: 0.0000\n",
      "Epoch 94/100, Step: 316/338, Total Loss: 0.0000\n",
      "Epoch 94, accuracy: 0.9617, validation Loss: 0.1434\n",
      "\n",
      "Epoch 95/100, Step: 28/338, Total Loss: 0.0000\n",
      "Epoch 95/100, Step: 78/338, Total Loss: 0.0000\n",
      "Epoch 95/100, Step: 128/338, Total Loss: 0.0000\n",
      "Epoch 95/100, Step: 178/338, Total Loss: 0.0000\n",
      "Epoch 95/100, Step: 228/338, Total Loss: 0.0000\n",
      "Epoch 95/100, Step: 278/338, Total Loss: 0.0000\n",
      "Epoch 95/100, Step: 328/338, Total Loss: 0.0000\n",
      "Epoch 95, accuracy: 0.9617, validation Loss: 0.1538\n",
      "\n",
      "Epoch 96/100, Step: 40/338, Total Loss: 0.0000\n",
      "Epoch 96/100, Step: 90/338, Total Loss: 0.0000\n",
      "Epoch 96/100, Step: 140/338, Total Loss: 0.0000\n",
      "Epoch 96/100, Step: 190/338, Total Loss: 0.0000\n",
      "Epoch 96/100, Step: 240/338, Total Loss: 0.0000\n",
      "Epoch 96/100, Step: 290/338, Total Loss: 0.0000\n",
      "Epoch 96, accuracy: 0.9617, validation Loss: 0.1435\n",
      "\n",
      "Epoch 97/100, Step: 2/338, Total Loss: 0.0000\n",
      "Epoch 97/100, Step: 52/338, Total Loss: 0.0000\n",
      "Epoch 97/100, Step: 102/338, Total Loss: 0.0000\n",
      "Epoch 97/100, Step: 152/338, Total Loss: 0.0000\n",
      "Epoch 97/100, Step: 202/338, Total Loss: 0.0000\n",
      "Epoch 97/100, Step: 252/338, Total Loss: 0.0000\n",
      "Epoch 97/100, Step: 302/338, Total Loss: 0.0000\n",
      "Epoch 97, accuracy: 0.9617, validation Loss: 0.1443\n",
      "\n",
      "Epoch 98/100, Step: 14/338, Total Loss: 0.0000\n",
      "Epoch 98/100, Step: 64/338, Total Loss: 0.0000\n",
      "Epoch 98/100, Step: 114/338, Total Loss: 0.0000\n",
      "Epoch 98/100, Step: 164/338, Total Loss: 0.0000\n",
      "Epoch 98/100, Step: 214/338, Total Loss: 0.0000\n",
      "Epoch 98/100, Step: 264/338, Total Loss: 0.0000\n",
      "Epoch 98/100, Step: 314/338, Total Loss: 0.0000\n",
      "Epoch 98, accuracy: 0.9600, validation Loss: 0.1425\n",
      "\n",
      "Epoch 99/100, Step: 26/338, Total Loss: 0.0000\n",
      "Epoch 99/100, Step: 76/338, Total Loss: 0.0000\n",
      "Epoch 99/100, Step: 126/338, Total Loss: 0.0000\n",
      "Epoch 99/100, Step: 176/338, Total Loss: 0.0000\n",
      "Epoch 99/100, Step: 226/338, Total Loss: 0.0000\n",
      "Epoch 99/100, Step: 276/338, Total Loss: 0.0000\n",
      "Epoch 99/100, Step: 326/338, Total Loss: 0.0000\n",
      "Epoch 99, accuracy: 0.9600, validation Loss: 0.1450\n",
      "\n",
      "Epoch 100/100, Step: 38/338, Total Loss: 0.0000\n",
      "Epoch 100/100, Step: 88/338, Total Loss: 0.0000\n",
      "Epoch 100/100, Step: 138/338, Total Loss: 0.0000\n",
      "Epoch 100/100, Step: 188/338, Total Loss: 0.0000\n",
      "Epoch 100/100, Step: 238/338, Total Loss: 0.0000\n",
      "Epoch 100/100, Step: 288/338, Total Loss: 0.0000\n",
      "Epoch 100/100, Step: 338/338, Total Loss: 0.0000\n",
      "Epoch 100, accuracy: 0.9600, validation Loss: 0.1427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Part\n",
    "\n",
    "# Switch to Training Mode\n",
    "model.train()\n",
    "\n",
    "# Clear Cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "total_loss = 0\n",
    "step = 0\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = to_device(inputs), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = citeria(outputs.view(-1), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        step += 1\n",
    "\n",
    "        if step % logging_per_step == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Step: {i+1}/{len(train_loader)}, Total Loss: {total_loss:.4f}')\n",
    "            total_loss = 0\n",
    "        \n",
    "        del inputs, targets\n",
    "    \n",
    "    accuracy, validation_loss = validate()\n",
    "    print(f'Epoch {epoch+1}, accuracy: {accuracy:.4f}, validation Loss: {validation_loss:.4f}\\n')\n",
    "    torch.save(model, model_dir / f'model_{epoch+1}.pt')\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, model_dir / f'model_best.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
